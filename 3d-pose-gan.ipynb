{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Initial code was copied from:\n",
    "https://github.com/jason71995/Keras-GAN-Library\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,GlobalAveragePooling2D,LeakyReLU,Conv2DTranspose,Activation,BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras import initializers\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "\n",
    "\n",
    "noise_dim = 5\n",
    "\n",
    "def build_generator(input_shape):\n",
    "\n",
    "    generator = Sequential()\n",
    "    \n",
    "    generator.add(Dense(512,\n",
    "                        input_dim = noise_dim))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(512))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "    generator.add(Dense(512))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    generator.add(Dense(105, activation='tanh'))\n",
    "    return generator\n",
    "\n",
    "\n",
    "def build_discriminator(input_shape):\n",
    "\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Dense(512,\n",
    "                            input_dim=105))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "    \n",
    "    \n",
    "    discriminator.add(Dense(512))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "    \n",
    "    discriminator.add(Dense(512))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "        \n",
    "\n",
    "    \n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return discriminator\n",
    "\n",
    "def build_functions(batch_size, noise_size, image_size, generator, discriminator):\n",
    "\n",
    "    noise = K.random_normal((batch_size,) + noise_size,0.0,1.0,\"float32\")\n",
    "    real_image = K.placeholder((batch_size,) + image_size)\n",
    "\n",
    "    fake_image = generator(noise)\n",
    "\n",
    "    d_input = K.concatenate([real_image, fake_image], axis=0)\n",
    "    pred_real, pred_fake = tf.split(discriminator(d_input), num_or_size_splits = 2, axis = 0)\n",
    "\n",
    "    pred_real = K.clip(pred_real,K.epsilon(),1-K.epsilon())\n",
    "    pred_fake = K.clip(pred_fake,K.epsilon(),1-K.epsilon())\n",
    "\n",
    "    d_loss = -(K.mean(K.log(pred_real)) + K.mean(K.log(1-pred_fake)))\n",
    "    g_loss = -K.mean(K.log(pred_fake))\n",
    "\n",
    "    # get updates of mean and variance in batch normalization layers\n",
    "    d_updates = discriminator.get_updates_for([d_input])\n",
    "    g_updates = generator.get_updates_for([noise])\n",
    "\n",
    "    d_training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(d_loss, discriminator.trainable_weights)\n",
    "    d_train = K.function([real_image, K.learning_phase()], [d_loss],d_updates + d_training_updates)\n",
    "\n",
    "    g_training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(g_loss, generator.trainable_weights)\n",
    "    g_train = K.function([real_image, K.learning_phase()], [g_loss], g_updates + g_training_updates)\n",
    "\n",
    "    return d_train,g_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117562, 105)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading MHAD data for action1, all persons and all repeatations of each person\n",
    "from utils.data_loader import data_loader\n",
    "data_object= data_loader(matlab_action_path='../gan/')\n",
    "myData, mymin, mymax = data_object.actions_normalised([1], twoD_true_or_threeD_false=False)\n",
    "myData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/201] d_loss: 0.1177, g_loss: 5.006\n",
      "[1/201] d_loss: 0.5727, g_loss: 2.061\n",
      "[2/201] d_loss: 0.9354, g_loss: 0.9107\n",
      "[3/201] d_loss: 0.7705, g_loss: 1.368\n",
      "[4/201] d_loss: 0.8884, g_loss: 1.955\n",
      "[5/201] d_loss: 0.2483, g_loss: 4.394\n",
      "[6/201] d_loss: 1.033, g_loss: 5.222\n",
      "[7/201] d_loss: 0.5924, g_loss: 3.895\n",
      "[8/201] d_loss: 0.4565, g_loss: 5.918\n",
      "[9/201] d_loss: 0.3956, g_loss: 7.552\n",
      "[10/201] d_loss: 0.3343, g_loss: 12.07\n",
      "[11/201] d_loss: 0.3504, g_loss: 8.971\n",
      "[12/201] d_loss: 0.3316, g_loss: 15.16\n",
      "[13/201] d_loss: 0.7324, g_loss: 12.74\n",
      "[14/201] d_loss: 0.3714, g_loss: 10.39\n",
      "[15/201] d_loss: 0.4401, g_loss: 9.443\n",
      "[16/201] d_loss: 0.2663, g_loss: 11.69\n",
      "[17/201] d_loss: 0.1676, g_loss: 12.44\n",
      "[18/201] d_loss: 0.3832, g_loss: 11.24\n",
      "[19/201] d_loss: 0.2605, g_loss: 12.1\n",
      "[20/201] d_loss: 0.389, g_loss: 8.463\n",
      "[21/201] d_loss: 0.3751, g_loss: 8.024\n",
      "[22/201] d_loss: 0.2836, g_loss: 9.151\n",
      "[23/201] d_loss: 0.4378, g_loss: 11.7\n",
      "[24/201] d_loss: 0.7543, g_loss: 7.212\n",
      "[25/201] d_loss: 0.9127, g_loss: 7.771\n",
      "[26/201] d_loss: 0.6449, g_loss: 9.504\n",
      "[27/201] d_loss: 0.7532, g_loss: 6.881\n",
      "[28/201] d_loss: 0.7506, g_loss: 6.284\n",
      "[29/201] d_loss: 0.3328, g_loss: 5.763\n",
      "[30/201] d_loss: 0.5648, g_loss: 6.677\n",
      "[31/201] d_loss: 1.595, g_loss: 3.667\n",
      "[32/201] d_loss: 0.8211, g_loss: 4.855\n",
      "[33/201] d_loss: 0.992, g_loss: 7.063\n",
      "[34/201] d_loss: 0.901, g_loss: 6.922\n",
      "[35/201] d_loss: 1.232, g_loss: 5.659\n",
      "[36/201] d_loss: 1.057, g_loss: 5.382\n",
      "[37/201] d_loss: 0.9891, g_loss: 3.984\n",
      "[38/201] d_loss: 1.009, g_loss: 5.707\n",
      "[39/201] d_loss: 1.013, g_loss: 4.526\n",
      "[40/201] d_loss: 0.9311, g_loss: 5.244\n",
      "[41/201] d_loss: 0.9238, g_loss: 5.309\n",
      "[42/201] d_loss: 1.377, g_loss: 4.711\n",
      "[43/201] d_loss: 1.291, g_loss: 4.532\n",
      "[44/201] d_loss: 1.221, g_loss: 4.372\n",
      "[45/201] d_loss: 1.31, g_loss: 4.341\n",
      "[46/201] d_loss: 1.227, g_loss: 4.178\n",
      "[47/201] d_loss: 0.7198, g_loss: 4.912\n",
      "[48/201] d_loss: 1.367, g_loss: 4.628\n",
      "[49/201] d_loss: 0.7542, g_loss: 5.809\n",
      "[50/201] d_loss: 0.8633, g_loss: 4.472\n",
      "[51/201] d_loss: 1.171, g_loss: 6.272\n",
      "[52/201] d_loss: 0.8437, g_loss: 4.237\n",
      "[53/201] d_loss: 0.864, g_loss: 4.251\n",
      "[54/201] d_loss: 1.1, g_loss: 5.125\n",
      "[55/201] d_loss: 1.093, g_loss: 4.18\n",
      "[56/201] d_loss: 1.008, g_loss: 2.651\n",
      "[57/201] d_loss: 1.236, g_loss: 6.96\n",
      "[58/201] d_loss: 1.292, g_loss: 4.931\n",
      "[59/201] d_loss: 0.7749, g_loss: 5.434\n",
      "[60/201] d_loss: 0.9065, g_loss: 2.698\n",
      "[61/201] d_loss: 1.04, g_loss: 3.877\n",
      "[62/201] d_loss: 0.9722, g_loss: 2.806\n",
      "[63/201] d_loss: 1.17, g_loss: 3.327\n",
      "[64/201] d_loss: 0.7161, g_loss: 2.567\n",
      "[65/201] d_loss: 1.097, g_loss: 3.744\n",
      "[66/201] d_loss: 1.205, g_loss: 5.631\n",
      "[67/201] d_loss: 0.9106, g_loss: 5.521\n",
      "[68/201] d_loss: 0.9702, g_loss: 3.582\n",
      "[69/201] d_loss: 1.061, g_loss: 4.067\n",
      "[70/201] d_loss: 0.9836, g_loss: 2.988\n",
      "[71/201] d_loss: 0.9023, g_loss: 4.804\n",
      "[72/201] d_loss: 0.9968, g_loss: 2.809\n",
      "[73/201] d_loss: 1.259, g_loss: 4.172\n",
      "[74/201] d_loss: 1.007, g_loss: 4.409\n",
      "[75/201] d_loss: 0.9356, g_loss: 4.789\n",
      "[76/201] d_loss: 0.9379, g_loss: 5.558\n",
      "[77/201] d_loss: 1.239, g_loss: 8.096\n",
      "[78/201] d_loss: 1.043, g_loss: 3.108\n",
      "[79/201] d_loss: 1.134, g_loss: 2.874\n",
      "[80/201] d_loss: 1.04, g_loss: 2.651\n",
      "[81/201] d_loss: 1.12, g_loss: 3.608\n",
      "[82/201] d_loss: 1.16, g_loss: 2.954\n",
      "[83/201] d_loss: 1.03, g_loss: 3.854\n",
      "[84/201] d_loss: 1.008, g_loss: 3.738\n",
      "[85/201] d_loss: 1.164, g_loss: 4.035\n",
      "[86/201] d_loss: 0.8128, g_loss: 7.183\n",
      "[87/201] d_loss: 1.231, g_loss: 4.996\n",
      "[88/201] d_loss: 0.8539, g_loss: 2.867\n",
      "[89/201] d_loss: 1.194, g_loss: 3.324\n",
      "[90/201] d_loss: 1.096, g_loss: 3.595\n",
      "[91/201] d_loss: 1.222, g_loss: 4.759\n",
      "[92/201] d_loss: 1.061, g_loss: 3.827\n",
      "[93/201] d_loss: 0.7613, g_loss: 8.328\n",
      "[94/201] d_loss: 0.7899, g_loss: 4.189\n",
      "[95/201] d_loss: 1.135, g_loss: 2.677\n",
      "[96/201] d_loss: 1.08, g_loss: 3.58\n",
      "[97/201] d_loss: 0.9113, g_loss: 4.664\n",
      "[98/201] d_loss: 1.175, g_loss: 3.089\n",
      "[99/201] d_loss: 0.9629, g_loss: 3.194\n",
      "[100/201] d_loss: 1.307, g_loss: 4.057\n",
      "[101/201] d_loss: 0.9433, g_loss: 2.644\n",
      "[102/201] d_loss: 0.9952, g_loss: 2.984\n",
      "[103/201] d_loss: 0.9686, g_loss: 2.792\n",
      "[104/201] d_loss: 0.9817, g_loss: 2.636\n",
      "[105/201] d_loss: 0.9331, g_loss: 2.885\n",
      "[106/201] d_loss: 0.978, g_loss: 3.509\n",
      "[107/201] d_loss: 1.187, g_loss: 4.957\n",
      "[108/201] d_loss: 0.9906, g_loss: 2.781\n",
      "[109/201] d_loss: 1.051, g_loss: 4.978\n",
      "[110/201] d_loss: 1.035, g_loss: 3.422\n",
      "[111/201] d_loss: 1.075, g_loss: 3.066\n",
      "[112/201] d_loss: 1.801, g_loss: 8.737\n",
      "[113/201] d_loss: 1.128, g_loss: 3.926\n",
      "[114/201] d_loss: 0.9671, g_loss: 5.652\n",
      "[115/201] d_loss: 1.318, g_loss: 3.654\n",
      "[116/201] d_loss: 1.088, g_loss: 3.59\n",
      "[117/201] d_loss: 1.239, g_loss: 3.596\n",
      "[118/201] d_loss: 1.169, g_loss: 3.384\n",
      "[119/201] d_loss: 1.128, g_loss: 3.951\n",
      "[120/201] d_loss: 0.9697, g_loss: 2.725\n",
      "[121/201] d_loss: 0.9108, g_loss: 2.97\n",
      "[122/201] d_loss: 0.9299, g_loss: 2.877\n",
      "[123/201] d_loss: 1.094, g_loss: 2.616\n",
      "[124/201] d_loss: 1.011, g_loss: 3.781\n",
      "[125/201] d_loss: 0.7286, g_loss: 9.849\n",
      "[126/201] d_loss: 0.877, g_loss: 2.895\n",
      "[127/201] d_loss: 0.8603, g_loss: 2.919\n",
      "[128/201] d_loss: 0.9818, g_loss: 3.321\n",
      "[129/201] d_loss: 1.033, g_loss: 4.258\n",
      "[130/201] d_loss: 0.9829, g_loss: 3.439\n",
      "[131/201] d_loss: 1.183, g_loss: 2.814\n",
      "[132/201] d_loss: 1.211, g_loss: 2.697\n",
      "[133/201] d_loss: 0.9954, g_loss: 2.77\n",
      "[134/201] d_loss: 0.7027, g_loss: 4.49\n",
      "[135/201] d_loss: 1.104, g_loss: 2.633\n",
      "[136/201] d_loss: 0.8898, g_loss: 3.026\n",
      "[137/201] d_loss: 1.282, g_loss: 2.71\n",
      "[138/201] d_loss: 1.072, g_loss: 2.838\n",
      "[139/201] d_loss: 1.344, g_loss: 7.554\n",
      "[140/201] d_loss: 0.9528, g_loss: 3.713\n",
      "[141/201] d_loss: 0.9896, g_loss: 4.026\n",
      "[142/201] d_loss: 0.9632, g_loss: 2.904\n",
      "[143/201] d_loss: 1.034, g_loss: 3.209\n",
      "[144/201] d_loss: 1.173, g_loss: 2.645\n",
      "[145/201] d_loss: 1.027, g_loss: 2.894\n",
      "[146/201] d_loss: 0.5802, g_loss: 3.479\n",
      "[147/201] d_loss: 1.09, g_loss: 4.179\n",
      "[148/201] d_loss: 1.129, g_loss: 2.795\n",
      "[149/201] d_loss: 1.231, g_loss: 2.663\n",
      "[150/201] d_loss: 1.359, g_loss: 3.542\n",
      "[151/201] d_loss: 0.7554, g_loss: 3.479\n",
      "[152/201] d_loss: 1.62, g_loss: 2.745\n",
      "[153/201] d_loss: 1.141, g_loss: 2.984\n",
      "[154/201] d_loss: 0.9895, g_loss: 2.801\n",
      "[155/201] d_loss: 1.026, g_loss: 3.04\n",
      "[156/201] d_loss: 1.182, g_loss: 2.145\n",
      "[157/201] d_loss: 1.165, g_loss: 4.342\n",
      "[158/201] d_loss: 1.087, g_loss: 4.078\n",
      "[159/201] d_loss: 1.162, g_loss: 3.121\n",
      "[160/201] d_loss: 1.359, g_loss: 2.862\n",
      "[161/201] d_loss: 0.8642, g_loss: 4.905\n",
      "[162/201] d_loss: 1.011, g_loss: 2.555\n",
      "[163/201] d_loss: 1.027, g_loss: 5.388\n",
      "[164/201] d_loss: 1.003, g_loss: 2.724\n",
      "[165/201] d_loss: 0.8961, g_loss: 2.804\n",
      "[166/201] d_loss: 1.022, g_loss: 3.291\n",
      "[167/201] d_loss: 1.313, g_loss: 4.561\n",
      "[168/201] d_loss: 1.176, g_loss: 3.578\n",
      "[169/201] d_loss: 0.9956, g_loss: 5.326\n",
      "[170/201] d_loss: 1.033, g_loss: 2.956\n",
      "[171/201] d_loss: 0.8684, g_loss: 2.588\n",
      "[172/201] d_loss: 1.329, g_loss: 4.058\n",
      "[173/201] d_loss: 1.308, g_loss: 2.971\n",
      "[174/201] d_loss: 1.179, g_loss: 3.666\n",
      "[175/201] d_loss: 1.115, g_loss: 3.024\n",
      "[176/201] d_loss: 0.8813, g_loss: 5.062\n",
      "[177/201] d_loss: 1.244, g_loss: 6.466\n",
      "[178/201] d_loss: 1.011, g_loss: 3.009\n",
      "[179/201] d_loss: 0.9612, g_loss: 3.982\n",
      "[180/201] d_loss: 1.083, g_loss: 7.918\n",
      "[181/201] d_loss: 1.11, g_loss: 3.533\n",
      "[182/201] d_loss: 0.9425, g_loss: 4.207\n",
      "[183/201] d_loss: 1.431, g_loss: 2.809\n",
      "[184/201] d_loss: 1.101, g_loss: 2.98\n",
      "[185/201] d_loss: 1.079, g_loss: 8.049\n",
      "[186/201] d_loss: 1.276, g_loss: 3.693\n",
      "[187/201] d_loss: 1.218, g_loss: 2.82\n",
      "[188/201] d_loss: 0.5783, g_loss: 3.169\n",
      "[189/201] d_loss: 1.142, g_loss: 2.859\n",
      "[190/201] d_loss: 1.161, g_loss: 3.058\n",
      "[191/201] d_loss: 1.077, g_loss: 2.66\n",
      "[192/201] d_loss: 1.129, g_loss: 3.273\n",
      "[193/201] d_loss: 0.9545, g_loss: 5.766\n",
      "[194/201] d_loss: 1.153, g_loss: 2.784\n",
      "[195/201] d_loss: 1.503, g_loss: 2.69\n",
      "[196/201] d_loss: 1.101, g_loss: 3.515\n",
      "[197/201] d_loss: 1.257, g_loss: 2.586\n",
      "[198/201] d_loss: 1.125, g_loss: 4.559\n",
      "[199/201] d_loss: 0.9089, g_loss: 4.635\n",
      "[200/201] d_loss: 1.148, g_loss: 2.809\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Number of parameter for the Generator and discriminator respectively:\n",
      "\n",
      "588393\n",
      "\n",
      "580097\n",
      "\n",
      "\n",
      "Number of Epochs and steps for each epoch:\n",
      "\n",
      "epochs:  201    Steps:  1000\n",
      "\n",
      "\n",
      "Time Taken:\n",
      "00:40:55\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "#from gan_libs.DCGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.LSGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.SNGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.WGAN_GP import build_generator, build_discriminator, build_functions\n",
    "\n",
    "from utils.common import set_gpu_config, predict_images\n",
    "from utils.draw_pose import draw_pose\n",
    "import numpy as np\n",
    "\n",
    "set_gpu_config(\"0\",0.5)\n",
    "\n",
    "epoch = 200 + 1\n",
    "steps = 1000\n",
    "image_size = (1,1,105)\n",
    "noise_size = (1,1,5)\n",
    "batch_size = 16\n",
    "\n",
    "x_train = myData\n",
    "\n",
    "generator = build_generator(noise_size)\n",
    "#print(generator.summary())\n",
    "discriminator = build_discriminator(image_size)\n",
    "#print(discriminator.summary())\n",
    "d_train, g_train = build_functions(batch_size, noise_size, image_size, generator, discriminator)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for e in range(epoch):\n",
    "    for s in range(steps):\n",
    "        real_images = x_train[np.random.permutation(x_train.shape[0])[:batch_size]]\n",
    "        real_images.shape = (batch_size,1,1,105)\n",
    "        d_loss, = d_train([real_images, 1])\n",
    "        g_loss, = g_train([real_images, 1])\n",
    "     \n",
    "    \n",
    "    print (\"[{0}/{1}] d_loss: {2:.4}, g_loss: {3:.4}\".format(e, epoch, d_loss, g_loss))\n",
    "    #generating a sample\n",
    "    image = generator.predict(np.zeros(shape=(1,5)))\n",
    "    image = np.array(image)\n",
    "    draw_pose(image.reshape(105),'output',\"e{0}\".format(e))\n",
    "        \n",
    "    if e % 100 == 0:\n",
    "        generator.save_weights(\"e{0}_generator.h5\".format(e))\n",
    "        discriminator.save_weights(\"e{0}_discriminator.h5\".format(e))\n",
    "        \n",
    "elapsed_time = time.time() - start_time \n",
    "print('\\n\\n\\n\\nNumber of parameter for the Generator and discriminator respectively:\\n')\n",
    "print(generator.count_params())\n",
    "print('')\n",
    "print(discriminator.count_params())\n",
    "print('\\n\\nNumber of Epochs and steps for each epoch:\\n')\n",
    "print('epochs: ',epoch, '   Steps: ', steps)\n",
    "\n",
    "print('\\n\\nTime Taken:')\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_weights(\"e400_generator.h5\".format(e))\n",
    "discriminator.load_weights(\"e400_discriminator.h5\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    x= np.array((i/100,0,0,0,0)).reshape(1,5)\n",
    "    image = generator.predict(x)\n",
    "    image = np.array(image)\n",
    "    draw_pose(image.reshape(105),'output',\"e{0}\".format(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

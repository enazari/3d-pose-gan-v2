{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Initial code was copied from:\n",
    "https://github.com/eurismarpires/Keras-GAN-1/blob/master/gan/gan.py\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks\n",
    "    Ref:\n",
    "        - https://arxiv.org/abs/1511.06434\n",
    "'''\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,GlobalAveragePooling2D,LeakyReLU,Conv2DTranspose,Activation,BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def build_generator(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2DTranspose(512,(3,3),strides=(2,2),padding=\"same\",input_shape=input_shape))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2DTranspose(256,(3,3),strides=(2,2),padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2DTranspose(128,(3,3),strides=(2,2),padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2DTranspose(64,(3,3),strides=(2,2),padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(3,(3,3),padding=\"same\",activation=\"tanh\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_discriminator(input_shape):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(64,(3,3),strides=(2,2),padding=\"same\",input_shape=input_shape))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(128,(3,3),strides=(2,2),padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(256,(3,3),strides=(2,2),padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(512,(3,3),strides=(2,2),padding=\"same\"))\n",
    "    model.add(LeakyReLU(0.2))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    model.add(Conv2D(1,(3,3),padding=\"same\"))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "\n",
    "    return model\n",
    "\n",
    "def build_functions(batch_size, noise_size, image_size, generator, discriminator):\n",
    "\n",
    "    noise = K.random_normal((batch_size,) + noise_size,0.0,1.0,\"float32\")\n",
    "    real_image = K.placeholder((batch_size,) + image_size)\n",
    "    fake_image = generator(noise)\n",
    "\n",
    "    d_input = K.concatenate([real_image, fake_image], axis=0)\n",
    "    pred_real, pred_fake = tf.split(discriminator(d_input), num_or_size_splits = 2, axis = 0)\n",
    "\n",
    "    pred_real = K.clip(pred_real,K.epsilon(),1-K.epsilon())\n",
    "    pred_fake = K.clip(pred_fake,K.epsilon(),1-K.epsilon())\n",
    "\n",
    "    d_loss = -(K.mean(K.log(pred_real)) + K.mean(K.log(1-pred_fake)))\n",
    "    g_loss = -K.mean(K.log(pred_fake))\n",
    "\n",
    "    # get updates of mean and variance in batch normalization layers\n",
    "    d_updates = discriminator.get_updates_for([d_input])\n",
    "    g_updates = generator.get_updates_for([noise])\n",
    "\n",
    "    d_training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(d_loss, discriminator.trainable_weights)\n",
    "    d_train = K.function([real_image, K.learning_phase()], [d_loss],d_updates + d_training_updates)\n",
    "\n",
    "    g_training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(g_loss, generator.trainable_weights)\n",
    "    g_train = K.function([real_image, K.learning_phase()], [g_loss], g_updates + g_training_updates)\n",
    "\n",
    "    return d_train,g_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "from gan_libs.DCGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.LSGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.SNGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.WGAN_GP import build_generator, build_discriminator, build_functions\n",
    "\n",
    "from utils.common import set_gpu_config, predict_images\n",
    "import numpy as np\n",
    "\n",
    "set_gpu_config(\"0\",0.5)\n",
    "\n",
    "epoch = 50\n",
    "steps = 1000\n",
    "image_size = (32,32,3)\n",
    "noise_size = (2,2,32)\n",
    "batch_size = 16\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "num_of_data = x_train.shape[0]\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train = (x_train/255)*2-1\n",
    "x_test = (x_test/255)*2-1\n",
    "y_train = keras.utils.to_categorical(y_train,10)\n",
    "y_test = keras.utils.to_categorical(y_test,10)\n",
    "\n",
    "generator = build_generator(noise_size)\n",
    "discriminator = build_discriminator(image_size)\n",
    "d_train, g_train = build_functions(batch_size, noise_size, image_size, generator, discriminator)\n",
    "\n",
    "for e in range(epoch):\n",
    "    for s in range(steps):\n",
    "        real_images = x_train[np.random.permutation(num_of_data)[:batch_size]]\n",
    "        d_loss, = d_train([real_images, 1])\n",
    "        g_loss, = g_train([real_images, 1])\n",
    "        print (\"[{0}/{1}] [{2}/{3}] d_loss: {4:.4}, g_loss: {5:.4}\".format(e, epoch, s, steps, d_loss, g_loss))\n",
    "\n",
    "    generator.save_weights(\"e{0}_generator.h5\".format(e))\n",
    "    predict_images(\"e{0}_img.png\".format(e), generator,noise_size,10,32)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

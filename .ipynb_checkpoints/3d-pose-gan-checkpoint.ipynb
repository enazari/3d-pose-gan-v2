{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Initial code was copied from:\n",
    "https://github.com/jason71995/Keras-GAN-Library\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,GlobalAveragePooling2D,LeakyReLU,Conv2DTranspose,Activation,BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras import initializers\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "\n",
    "\n",
    "noise_dim = 5\n",
    "\n",
    "def build_generator(input_shape):\n",
    "\n",
    "    generator = Sequential()\n",
    "    \n",
    "    generator.add(Dense(256,\n",
    "                        input_dim = noise_dim))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "#     generator.add(Dense(512))\n",
    "#     generator.add(BatchNormalization())\n",
    "#     generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    generator.add(Dense(105, activation='tanh'))\n",
    "    return generator\n",
    "\n",
    "\n",
    "def build_discriminator(input_shape):\n",
    "\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Dense(256,\n",
    "                            input_dim=105))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "    \n",
    "    \n",
    "#     discriminator.add(Dense(512))\n",
    "#     discriminator.add(LeakyReLU(0.2))\n",
    "#     discriminator.add(Dropout(0.3))\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return discriminator\n",
    "\n",
    "def build_functions(batch_size, noise_size, image_size, generator, discriminator):\n",
    "\n",
    "    noise = K.random_normal((batch_size,) + noise_size,0.0,1.0,\"float32\")\n",
    "    real_image = K.placeholder((batch_size,) + image_size)\n",
    "\n",
    "    fake_image = generator(noise)\n",
    "\n",
    "    d_input = K.concatenate([real_image, fake_image], axis=0)\n",
    "    pred_real, pred_fake = tf.split(discriminator(d_input), num_or_size_splits = 2, axis = 0)\n",
    "\n",
    "    pred_real = K.clip(pred_real,K.epsilon(),1-K.epsilon())\n",
    "    pred_fake = K.clip(pred_fake,K.epsilon(),1-K.epsilon())\n",
    "\n",
    "    d_loss = -(K.mean(K.log(pred_real)) + K.mean(K.log(1-pred_fake)))\n",
    "    g_loss = -K.mean(K.log(pred_fake))\n",
    "\n",
    "    # get updates of mean and variance in batch normalization layers\n",
    "    d_updates = discriminator.get_updates_for([d_input])\n",
    "    g_updates = generator.get_updates_for([noise])\n",
    "\n",
    "    d_training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(d_loss, discriminator.trainable_weights)\n",
    "    d_train = K.function([real_image, K.learning_phase()], [d_loss],d_updates + d_training_updates)\n",
    "\n",
    "    g_training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(g_loss, generator.trainable_weights)\n",
    "    g_train = K.function([real_image, K.learning_phase()], [g_loss], g_updates + g_training_updates)\n",
    "\n",
    "    return d_train,g_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117562, 105)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading MHAD data for action1, all persons and all repeatations of each person\n",
    "from utils.data_loader import data_loader\n",
    "data_object= data_loader(matlab_action_path='../gan/')\n",
    "myData, mymin, mymax = data_object.actions_normalised([1], twoD_true_or_threeD_false=False)\n",
    "myData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/201] d_loss: 1.212, g_loss: 0.9394\n",
      "[1/201] d_loss: 1.171, g_loss: 0.7916\n",
      "[2/201] d_loss: 1.174, g_loss: 0.8628\n",
      "[3/201] d_loss: 1.147, g_loss: 0.818\n",
      "[4/201] d_loss: 1.105, g_loss: 0.8702\n",
      "[5/201] d_loss: 1.147, g_loss: 0.9334\n",
      "[6/201] d_loss: 1.077, g_loss: 1.09\n",
      "[7/201] d_loss: 1.208, g_loss: 0.9167\n",
      "[8/201] d_loss: 1.242, g_loss: 0.79\n",
      "[9/201] d_loss: 1.251, g_loss: 0.7698\n",
      "[10/201] d_loss: 1.242, g_loss: 0.8775\n",
      "[11/201] d_loss: 1.306, g_loss: 0.8635\n",
      "[12/201] d_loss: 1.241, g_loss: 0.7639\n",
      "[13/201] d_loss: 1.237, g_loss: 0.8429\n",
      "[14/201] d_loss: 1.337, g_loss: 0.8383\n",
      "[15/201] d_loss: 1.338, g_loss: 0.7323\n",
      "[16/201] d_loss: 1.325, g_loss: 0.795\n",
      "[17/201] d_loss: 1.317, g_loss: 0.8224\n",
      "[18/201] d_loss: 1.372, g_loss: 0.7771\n",
      "[19/201] d_loss: 1.31, g_loss: 0.6861\n",
      "[20/201] d_loss: 1.339, g_loss: 0.7756\n",
      "[21/201] d_loss: 1.355, g_loss: 0.6889\n",
      "[22/201] d_loss: 1.305, g_loss: 0.7177\n",
      "[23/201] d_loss: 1.282, g_loss: 0.7303\n",
      "[24/201] d_loss: 1.357, g_loss: 0.7027\n",
      "[25/201] d_loss: 1.326, g_loss: 0.7827\n",
      "[26/201] d_loss: 1.325, g_loss: 0.7877\n",
      "[27/201] d_loss: 1.377, g_loss: 0.7532\n",
      "[28/201] d_loss: 1.318, g_loss: 0.7914\n",
      "[29/201] d_loss: 1.36, g_loss: 0.7671\n",
      "[30/201] d_loss: 1.332, g_loss: 0.7776\n",
      "[31/201] d_loss: 1.357, g_loss: 0.7048\n",
      "[32/201] d_loss: 1.335, g_loss: 0.701\n",
      "[33/201] d_loss: 1.37, g_loss: 0.7278\n",
      "[34/201] d_loss: 1.342, g_loss: 0.7699\n",
      "[35/201] d_loss: 1.339, g_loss: 0.7303\n",
      "[36/201] d_loss: 1.336, g_loss: 0.7624\n",
      "[37/201] d_loss: 1.37, g_loss: 0.7074\n",
      "[38/201] d_loss: 1.329, g_loss: 0.7494\n",
      "[39/201] d_loss: 1.324, g_loss: 0.8185\n",
      "[40/201] d_loss: 1.255, g_loss: 0.7639\n",
      "[41/201] d_loss: 1.255, g_loss: 0.7378\n",
      "[42/201] d_loss: 1.339, g_loss: 0.7837\n",
      "[43/201] d_loss: 1.303, g_loss: 0.7992\n",
      "[44/201] d_loss: 1.246, g_loss: 0.8847\n",
      "[45/201] d_loss: 1.256, g_loss: 0.7643\n",
      "[46/201] d_loss: 1.337, g_loss: 0.7792\n",
      "[47/201] d_loss: 1.289, g_loss: 0.7499\n",
      "[48/201] d_loss: 1.327, g_loss: 0.7732\n",
      "[49/201] d_loss: 1.281, g_loss: 0.7376\n",
      "[50/201] d_loss: 1.308, g_loss: 0.7754\n",
      "[51/201] d_loss: 1.298, g_loss: 0.7874\n",
      "[52/201] d_loss: 1.297, g_loss: 0.7281\n",
      "[53/201] d_loss: 1.24, g_loss: 0.9339\n",
      "[54/201] d_loss: 1.308, g_loss: 0.7938\n",
      "[55/201] d_loss: 1.289, g_loss: 0.8071\n",
      "[56/201] d_loss: 1.288, g_loss: 0.8948\n",
      "[57/201] d_loss: 1.267, g_loss: 0.8718\n",
      "[58/201] d_loss: 1.255, g_loss: 0.8246\n",
      "[59/201] d_loss: 1.265, g_loss: 0.8865\n",
      "[60/201] d_loss: 1.257, g_loss: 0.8261\n",
      "[61/201] d_loss: 1.244, g_loss: 0.902\n",
      "[62/201] d_loss: 1.228, g_loss: 0.7648\n",
      "[63/201] d_loss: 1.263, g_loss: 0.9239\n",
      "[64/201] d_loss: 1.3, g_loss: 0.8263\n",
      "[65/201] d_loss: 1.26, g_loss: 0.88\n",
      "[66/201] d_loss: 1.14, g_loss: 0.8101\n",
      "[67/201] d_loss: 1.204, g_loss: 0.9282\n",
      "[68/201] d_loss: 1.263, g_loss: 0.8913\n",
      "[69/201] d_loss: 1.231, g_loss: 0.8015\n",
      "[70/201] d_loss: 1.19, g_loss: 0.896\n",
      "[71/201] d_loss: 1.189, g_loss: 1.004\n",
      "[72/201] d_loss: 1.13, g_loss: 0.8697\n",
      "[73/201] d_loss: 1.248, g_loss: 0.9749\n",
      "[74/201] d_loss: 1.169, g_loss: 0.9808\n",
      "[75/201] d_loss: 1.237, g_loss: 0.8815\n",
      "[76/201] d_loss: 1.21, g_loss: 0.9024\n",
      "[77/201] d_loss: 1.2, g_loss: 0.8698\n",
      "[78/201] d_loss: 1.118, g_loss: 0.9872\n",
      "[79/201] d_loss: 1.137, g_loss: 0.9619\n",
      "[80/201] d_loss: 1.043, g_loss: 1.052\n",
      "[81/201] d_loss: 1.104, g_loss: 1.081\n",
      "[82/201] d_loss: 1.13, g_loss: 0.8804\n",
      "[83/201] d_loss: 1.107, g_loss: 1.051\n",
      "[84/201] d_loss: 1.127, g_loss: 1.014\n",
      "[85/201] d_loss: 1.157, g_loss: 0.9961\n",
      "[86/201] d_loss: 1.058, g_loss: 0.8787\n",
      "[87/201] d_loss: 1.153, g_loss: 0.9953\n",
      "[88/201] d_loss: 1.037, g_loss: 1.171\n",
      "[89/201] d_loss: 1.097, g_loss: 1.109\n",
      "[90/201] d_loss: 1.139, g_loss: 1.224\n",
      "[91/201] d_loss: 1.152, g_loss: 1.008\n",
      "[92/201] d_loss: 1.008, g_loss: 1.184\n",
      "[93/201] d_loss: 1.001, g_loss: 1.337\n",
      "[94/201] d_loss: 1.013, g_loss: 1.189\n",
      "[95/201] d_loss: 1.054, g_loss: 1.344\n",
      "[96/201] d_loss: 0.9478, g_loss: 1.163\n",
      "[97/201] d_loss: 0.9767, g_loss: 1.156\n",
      "[98/201] d_loss: 0.9549, g_loss: 1.462\n",
      "[99/201] d_loss: 0.9685, g_loss: 1.155\n",
      "[100/201] d_loss: 1.052, g_loss: 1.152\n",
      "[101/201] d_loss: 1.08, g_loss: 1.058\n",
      "[102/201] d_loss: 1.069, g_loss: 1.274\n",
      "[103/201] d_loss: 0.8384, g_loss: 1.461\n",
      "[104/201] d_loss: 0.909, g_loss: 1.248\n",
      "[105/201] d_loss: 0.9487, g_loss: 1.106\n",
      "[106/201] d_loss: 0.9583, g_loss: 1.284\n",
      "[107/201] d_loss: 1.067, g_loss: 1.045\n",
      "[108/201] d_loss: 1.023, g_loss: 1.239\n",
      "[109/201] d_loss: 1.005, g_loss: 1.259\n",
      "[110/201] d_loss: 0.9015, g_loss: 1.433\n",
      "[111/201] d_loss: 1.029, g_loss: 1.02\n",
      "[112/201] d_loss: 0.9069, g_loss: 1.345\n",
      "[113/201] d_loss: 0.8744, g_loss: 1.4\n",
      "[114/201] d_loss: 0.9009, g_loss: 1.109\n",
      "[115/201] d_loss: 0.8881, g_loss: 1.63\n",
      "[116/201] d_loss: 0.9069, g_loss: 1.33\n",
      "[117/201] d_loss: 0.9541, g_loss: 1.236\n",
      "[118/201] d_loss: 0.9512, g_loss: 1.478\n",
      "[119/201] d_loss: 0.9039, g_loss: 1.26\n",
      "[120/201] d_loss: 0.7613, g_loss: 1.221\n",
      "[121/201] d_loss: 0.8623, g_loss: 1.353\n",
      "[122/201] d_loss: 0.9012, g_loss: 1.338\n",
      "[123/201] d_loss: 0.8718, g_loss: 2.01\n",
      "[124/201] d_loss: 0.9425, g_loss: 1.07\n",
      "[125/201] d_loss: 0.8116, g_loss: 1.861\n",
      "[126/201] d_loss: 0.7813, g_loss: 1.833\n",
      "[127/201] d_loss: 0.9476, g_loss: 1.165\n",
      "[128/201] d_loss: 0.8619, g_loss: 1.308\n",
      "[129/201] d_loss: 0.9564, g_loss: 1.292\n",
      "[130/201] d_loss: 0.854, g_loss: 1.623\n",
      "[131/201] d_loss: 0.9895, g_loss: 1.502\n",
      "[132/201] d_loss: 0.7526, g_loss: 1.499\n",
      "[133/201] d_loss: 0.8697, g_loss: 1.293\n",
      "[134/201] d_loss: 0.7134, g_loss: 1.722\n",
      "[135/201] d_loss: 0.704, g_loss: 1.849\n",
      "[136/201] d_loss: 0.7826, g_loss: 1.842\n",
      "[137/201] d_loss: 0.7489, g_loss: 1.988\n",
      "[138/201] d_loss: 0.9107, g_loss: 1.864\n",
      "[139/201] d_loss: 0.6701, g_loss: 2.116\n",
      "[140/201] d_loss: 0.6662, g_loss: 1.841\n",
      "[141/201] d_loss: 0.5953, g_loss: 1.791\n",
      "[142/201] d_loss: 0.6192, g_loss: 2.228\n",
      "[143/201] d_loss: 0.7376, g_loss: 2.168\n",
      "[144/201] d_loss: 1.028, g_loss: 1.314\n",
      "[145/201] d_loss: 0.9174, g_loss: 1.552\n",
      "[146/201] d_loss: 1.086, g_loss: 1.427\n",
      "[147/201] d_loss: 0.586, g_loss: 2.093\n",
      "[148/201] d_loss: 0.8837, g_loss: 2.796\n",
      "[149/201] d_loss: 0.8079, g_loss: 1.579\n",
      "[150/201] d_loss: 0.7438, g_loss: 1.726\n",
      "[151/201] d_loss: 0.8335, g_loss: 1.537\n",
      "[152/201] d_loss: 0.7073, g_loss: 1.689\n",
      "[153/201] d_loss: 0.9011, g_loss: 2.165\n",
      "[154/201] d_loss: 0.8233, g_loss: 1.539\n",
      "[155/201] d_loss: 0.7264, g_loss: 2.092\n",
      "[156/201] d_loss: 0.8271, g_loss: 1.409\n",
      "[157/201] d_loss: 0.8833, g_loss: 1.721\n",
      "[158/201] d_loss: 0.9981, g_loss: 1.164\n",
      "[159/201] d_loss: 0.8407, g_loss: 2.707\n",
      "[160/201] d_loss: 0.7201, g_loss: 2.475\n",
      "[161/201] d_loss: 0.8056, g_loss: 2.07\n",
      "[162/201] d_loss: 0.6277, g_loss: 2.346\n",
      "[163/201] d_loss: 0.9548, g_loss: 1.902\n",
      "[164/201] d_loss: 0.8265, g_loss: 2.158\n",
      "[165/201] d_loss: 1.205, g_loss: 1.558\n",
      "[166/201] d_loss: 0.6277, g_loss: 2.024\n",
      "[167/201] d_loss: 0.6708, g_loss: 1.567\n",
      "[168/201] d_loss: 1.002, g_loss: 2.081\n",
      "[169/201] d_loss: 0.6666, g_loss: 1.59\n",
      "[170/201] d_loss: 0.6093, g_loss: 2.54\n",
      "[171/201] d_loss: 1.132, g_loss: 1.668\n",
      "[172/201] d_loss: 0.663, g_loss: 1.733\n",
      "[173/201] d_loss: 0.8576, g_loss: 1.634\n",
      "[174/201] d_loss: 0.6733, g_loss: 3.211\n",
      "[175/201] d_loss: 0.8753, g_loss: 1.638\n",
      "[176/201] d_loss: 1.004, g_loss: 1.243\n",
      "[177/201] d_loss: 0.8058, g_loss: 2.316\n",
      "[178/201] d_loss: 0.7128, g_loss: 2.093\n",
      "[179/201] d_loss: 0.8945, g_loss: 1.602\n",
      "[180/201] d_loss: 0.9617, g_loss: 1.558\n",
      "[181/201] d_loss: 0.8685, g_loss: 2.559\n",
      "[182/201] d_loss: 0.7204, g_loss: 2.481\n",
      "[183/201] d_loss: 1.168, g_loss: 0.8013\n",
      "[184/201] d_loss: 0.7252, g_loss: 2.068\n",
      "[185/201] d_loss: 0.9535, g_loss: 1.832\n",
      "[186/201] d_loss: 0.9578, g_loss: 1.841\n",
      "[187/201] d_loss: 0.5735, g_loss: 2.45\n",
      "[188/201] d_loss: 0.6887, g_loss: 2.214\n",
      "[189/201] d_loss: 1.087, g_loss: 1.523\n",
      "[190/201] d_loss: 0.6887, g_loss: 1.928\n",
      "[191/201] d_loss: 0.7737, g_loss: 2.332\n",
      "[192/201] d_loss: 1.043, g_loss: 2.36\n",
      "[193/201] d_loss: 1.033, g_loss: 1.543\n",
      "[194/201] d_loss: 0.6559, g_loss: 1.943\n",
      "[195/201] d_loss: 0.709, g_loss: 1.926\n",
      "[196/201] d_loss: 0.739, g_loss: 3.263\n",
      "[197/201] d_loss: 0.7521, g_loss: 2.207\n",
      "[198/201] d_loss: 0.7034, g_loss: 1.173\n",
      "[199/201] d_loss: 0.8886, g_loss: 1.689\n",
      "[200/201] d_loss: 0.8515, g_loss: 2.517\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Number of parameter for the Generator and discriminator respectively:\n",
      "\n",
      "29545\n",
      "\n",
      "27393\n",
      "\n",
      "\n",
      "Number of Epochs and steps for each epoch:\n",
      "\n",
      "epochs:  201    Steps:  1000\n",
      "\n",
      "\n",
      "Time Taken:\n",
      "00:30:17\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "#from gan_libs.DCGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.LSGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.SNGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.WGAN_GP import build_generator, build_discriminator, build_functions\n",
    "\n",
    "from utils.common import set_gpu_config, predict_images\n",
    "from utils.draw_pose import draw_pose\n",
    "import numpy as np\n",
    "\n",
    "set_gpu_config(\"0\",0.5)\n",
    "\n",
    "epoch = 200 + 1\n",
    "steps = 1000\n",
    "image_size = (1,1,105)\n",
    "noise_size = (1,1,5)\n",
    "batch_size = 16\n",
    "\n",
    "x_train = myData\n",
    "\n",
    "generator = build_generator(noise_size)\n",
    "#print(generator.summary())\n",
    "discriminator = build_discriminator(image_size)\n",
    "#print(discriminator.summary())\n",
    "d_train, g_train = build_functions(batch_size, noise_size, image_size, generator, discriminator)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for e in range(epoch):\n",
    "    for s in range(steps):\n",
    "        real_images = x_train[np.random.permutation(x_train.shape[0])[:batch_size]]\n",
    "        real_images.shape = (batch_size,1,1,105)\n",
    "        d_loss, = d_train([real_images, 1])\n",
    "        g_loss, = g_train([real_images, 1])\n",
    "     \n",
    "    \n",
    "    print (\"[{0}/{1}] d_loss: {2:.4}, g_loss: {3:.4}\".format(e, epoch, d_loss, g_loss))\n",
    "    #generating a sample\n",
    "    image = generator.predict(np.zeros(shape=(1,5)))\n",
    "    image = np.array(image)\n",
    "    draw_pose(image.reshape(105),'output',\"e{0}\".format(e))\n",
    "        \n",
    "    if e % 200 == 0:\n",
    "        generator.save_weights(\"e{0}_generator.h5\".format(e))\n",
    "        discriminator.save_weights(\"e{0}_discriminator.h5\".format(e))\n",
    " \n",
    "#just monitoring:\n",
    "##########################################################################################\n",
    "elapsed_time = time.time() - start_time \n",
    "print('\\n\\n\\n\\nNumber of parameter for the Generator and discriminator respectively:\\n')\n",
    "print(generator.count_params())\n",
    "print('')\n",
    "print(discriminator.count_params())\n",
    "print('\\n\\nNumber of Epochs and steps for each epoch:\\n')\n",
    "print('epochs: ',epoch, '   Steps: ', steps)\n",
    "\n",
    "print('\\n\\nTime Taken:')\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "##########################################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[37mcbrc-All-Series\u001b[m  Mon May  6 14:40:03 2019\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 53'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 6283\u001b[m / \u001b[33m11172\u001b[m MB | \u001b[1m\u001b[30mcbrc\u001b[m(\u001b[33m5961M\u001b[m) \u001b[1m\u001b[30mgdm\u001b[m(\u001b[33m16M\u001b[m) \u001b[1m\u001b[30mgdm\u001b[m(\u001b[33m50M\u001b[m) \u001b[1m\u001b[30mcbrc\u001b[m(\u001b[33m114M\u001b[m) \u001b[1m\u001b[30mcbrc\u001b[m(\u001b[33m136M\u001b[m)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    #gpu details:\n",
    "    ################----------------------------\n",
    "from six.moves import cStringIO as StringIO\n",
    "import gpustat\n",
    "\n",
    "gpustats = gpustat.new_query()\n",
    "fp = StringIO()\n",
    "gpustats.print_formatted(\n",
    "     fp=fp, no_color=False, show_user=False,\n",
    "     show_cmd=False, show_pid=False, show_power=False, show_fan_speed=False)\n",
    "\n",
    "result = fp.getvalue()\n",
    "print('\\n\\n')\n",
    "print(result)\n",
    "    ################----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_weights(\"e400_generator.h5\".format(e))\n",
    "discriminator.load_weights(\"e400_discriminator.h5\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    x= np.array((i/100,0,0,0,0)).reshape(1,5)\n",
    "    image = generator.predict(x)\n",
    "    image = np.array(image)\n",
    "    draw_pose(image.reshape(105),'output',\"e{0}\".format(i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nInitial code was copied from:\\nhttps://github.com/jason71995/Keras-GAN-Library\\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Initial code was copied from:\n",
    "https://github.com/jason71995/Keras-GAN-Library\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,GlobalAveragePooling2D,LeakyReLU,Conv2DTranspose,Activation,BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras import initializers\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "\n",
    "\n",
    "noise_dim = 3\n",
    "\n",
    "def build_generator(input_shape):\n",
    "\n",
    "    generator = Sequential()\n",
    "    \n",
    "    generator.add(Dense(256,\n",
    "                        input_dim = noise_dim))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "#     generator.add(Dense(256))\n",
    "#     generator.add(BatchNormalization())\n",
    "#     generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    generator.add(Dense(105, activation='tanh'))\n",
    "    return generator\n",
    "\n",
    "\n",
    "def build_discriminator(input_shape):\n",
    "\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Dense(256,\n",
    "                            input_dim=105))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "    \n",
    "    \n",
    "#     discriminator.add(Dense(256))\n",
    "#     discriminator.add(LeakyReLU(0.2))\n",
    "#     discriminator.add(Dropout(0.3))\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return discriminator\n",
    "\n",
    "def build_functions(batch_size, noise_size, image_size, generator, discriminator):\n",
    "\n",
    "    noise = K.random_normal((batch_size,) + noise_size,0.0,1.0,\"float32\")\n",
    "    real_image = K.placeholder((batch_size,) + image_size)\n",
    "\n",
    "    fake_image = generator(noise)\n",
    "\n",
    "    d_input = K.concatenate([real_image, fake_image], axis=0)\n",
    "    pred_real, pred_fake = tf.split(discriminator(d_input), num_or_size_splits = 2, axis = 0)\n",
    "\n",
    "    pred_real = K.clip(pred_real,K.epsilon(),1-K.epsilon())\n",
    "    pred_fake = K.clip(pred_fake,K.epsilon(),1-K.epsilon())\n",
    "\n",
    "    d_loss = -(K.mean(K.log(pred_real)) + K.mean(K.log(1-pred_fake)))\n",
    "    g_loss = -K.mean(K.log(pred_fake))\n",
    "\n",
    "    # get updates of mean and variance in batch normalization layers\n",
    "    d_updates = discriminator.get_updates_for([d_input])\n",
    "    g_updates = generator.get_updates_for([noise])\n",
    "\n",
    "    d_training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(d_loss, discriminator.trainable_weights)\n",
    "    d_train = K.function([real_image, K.learning_phase()], [d_loss],d_updates + d_training_updates)\n",
    "\n",
    "    g_training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(g_loss, generator.trainable_weights)\n",
    "    g_train = K.function([real_image, K.learning_phase()], [g_loss], g_updates + g_training_updates)\n",
    "\n",
    "    return d_train,g_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117562, 105)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading MHAD data for action1, all persons and all repeatations of each person\n",
    "from utils.data_loader import data_loader\n",
    "data_object= data_loader(matlab_action_path='../gan/')\n",
    "myData, mymin, mymax = data_object.actions_normalised([1], twoD_true_or_threeD_false=False)\n",
    "myData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gen params: 29545\n",
      "dis params: 27393\n",
      "Number of Batches passed in each epoch:  7347\n",
      "[0/6] d_loss: 1.409, g_loss: 0.7943\n",
      "[0/6] d_loss: 1.407, g_loss: 0.9419\n",
      "[0/6] d_loss: 2.132, g_loss: 0.495\n",
      "[0/6] d_loss: 1.86, g_loss: 0.8709\n",
      "[0/6] d_loss: 2.174, g_loss: 0.8676\n",
      "[0/6] d_loss: 1.63, g_loss: 0.3947\n",
      "[0/6] d_loss: 1.606, g_loss: 1.06\n",
      "[0/6] d_loss: 1.505, g_loss: 2.139\n",
      "[0/6] d_loss: 1.006, g_loss: 1.047\n",
      "[0/6] d_loss: 1.693, g_loss: 1.105\n",
      "[0/6] d_loss: 1.689, g_loss: 1.094\n",
      "[0/6] d_loss: 1.544, g_loss: 0.9577\n",
      "[0/6] d_loss: 1.362, g_loss: 0.7815\n",
      "[0/6] d_loss: 1.258, g_loss: 1.473\n",
      "[0/6] d_loss: 1.901, g_loss: 1.975\n",
      "[0/6] d_loss: 1.762, g_loss: 1.336\n",
      "[0/6] d_loss: 1.169, g_loss: 1.018\n",
      "[0/6] d_loss: 1.295, g_loss: 1.537\n",
      "[0/6] d_loss: 1.644, g_loss: 2.342\n",
      "[0/6] d_loss: 1.002, g_loss: 2.061\n",
      "[0/6] d_loss: 1.308, g_loss: 1.907\n",
      "[0/6] d_loss: 1.192, g_loss: 1.498\n",
      "[0/6] d_loss: 1.027, g_loss: 2.521\n",
      "[0/6] d_loss: 1.837, g_loss: 2.183\n",
      "[0/6] d_loss: 1.551, g_loss: 1.056\n",
      "[0/6] d_loss: 0.9735, g_loss: 1.813\n",
      "[0/6] d_loss: 2.064, g_loss: 1.496\n",
      "[0/6] d_loss: 1.522, g_loss: 1.445\n",
      "[0/6] d_loss: 1.243, g_loss: 1.273\n",
      "[0/6] d_loss: 1.134, g_loss: 1.051\n",
      "[0/6] d_loss: 1.229, g_loss: 1.447\n",
      "[0/6] d_loss: 1.207, g_loss: 1.329\n",
      "[0/6] d_loss: 1.189, g_loss: 0.8841\n",
      "[0/6] d_loss: 1.878, g_loss: 0.6294\n",
      "[0/6] d_loss: 1.023, g_loss: 0.9736\n",
      "[0/6] d_loss: 1.076, g_loss: 1.84\n",
      "[0/6] d_loss: 1.241, g_loss: 1.818\n",
      "[0/6] d_loss: 1.521, g_loss: 0.5481\n",
      "[0/6] d_loss: 0.8099, g_loss: 2.608\n",
      "[0/6] d_loss: 1.835, g_loss: 2.038\n",
      "[0/6] d_loss: 0.9075, g_loss: 1.429\n",
      "[0/6] d_loss: 1.553, g_loss: 2.19\n",
      "[0/6] d_loss: 1.432, g_loss: 0.4541\n",
      "[0/6] d_loss: 1.219, g_loss: 1.759\n",
      "[0/6] d_loss: 1.561, g_loss: 1.884\n",
      "[0/6] d_loss: 0.7906, g_loss: 1.248\n",
      "[0/6] d_loss: 1.403, g_loss: 1.211\n",
      "[0/6] d_loss: 1.159, g_loss: 1.039\n",
      "[0/6] d_loss: 1.003, g_loss: 1.285\n",
      "[0/6] d_loss: 0.9414, g_loss: 1.221\n",
      "[0/6] d_loss: 1.116, g_loss: 1.925\n",
      "[0/6] d_loss: 1.221, g_loss: 1.444\n",
      "[0/6] d_loss: 0.7222, g_loss: 1.394\n",
      "[0/6] d_loss: 1.085, g_loss: 1.35\n",
      "[0/6] d_loss: 0.8606, g_loss: 1.75\n",
      "[0/6] d_loss: 0.8502, g_loss: 2.156\n",
      "[0/6] d_loss: 1.883, g_loss: 1.363\n",
      "[0/6] d_loss: 0.8775, g_loss: 1.768\n",
      "[0/6] d_loss: 0.7854, g_loss: 1.389\n",
      "[0/6] d_loss: 1.265, g_loss: 1.865\n",
      "[0/6] d_loss: 1.289, g_loss: 0.6102\n",
      "[0/6] d_loss: 0.9723, g_loss: 1.769\n",
      "[0/6] d_loss: 1.095, g_loss: 2.394\n",
      "[0/6] d_loss: 0.6899, g_loss: 2.514\n",
      "[0/6] d_loss: 0.5955, g_loss: 2.661\n",
      "[0/6] d_loss: 0.8669, g_loss: 1.657\n",
      "[0/6] d_loss: 0.7768, g_loss: 1.843\n",
      "[0/6] d_loss: 0.7391, g_loss: 1.226\n",
      "[0/6] d_loss: 0.9862, g_loss: 1.538\n",
      "[0/6] d_loss: 1.189, g_loss: 1.475\n",
      "[0/6] d_loss: 1.033, g_loss: 1.311\n",
      "[0/6] d_loss: 0.7672, g_loss: 2.338\n",
      "[0/6] d_loss: 1.16, g_loss: 1.451\n",
      "[0/6] d_loss: 0.9662, g_loss: 1.496\n",
      "[0/6] d_loss: 0.869, g_loss: 1.886\n",
      "[0/6] d_loss: 0.8141, g_loss: 2.507\n",
      "[0/6] d_loss: 1.037, g_loss: 2.102\n",
      "\n",
      "\n",
      "Time Taken for single epoch:\n",
      "00:01:12\n",
      "[1/6] d_loss: 0.9824, g_loss: 0.8136\n",
      "[1/6] d_loss: 1.227, g_loss: 1.7\n",
      "[1/6] d_loss: 1.124, g_loss: 1.022\n",
      "[1/6] d_loss: 1.144, g_loss: 1.163\n",
      "[1/6] d_loss: 1.002, g_loss: 1.379\n",
      "[1/6] d_loss: 1.156, g_loss: 0.7182\n",
      "[1/6] d_loss: 1.127, g_loss: 0.9244\n",
      "[1/6] d_loss: 0.6674, g_loss: 2.072\n",
      "[1/6] d_loss: 1.303, g_loss: 1.71\n",
      "[1/6] d_loss: 1.155, g_loss: 2.003\n",
      "[1/6] d_loss: 0.8013, g_loss: 1.571\n",
      "[1/6] d_loss: 0.7545, g_loss: 1.826\n",
      "[1/6] d_loss: 1.762, g_loss: 2.8\n",
      "[1/6] d_loss: 0.8558, g_loss: 2.174\n",
      "[1/6] d_loss: 1.131, g_loss: 1.363\n",
      "[1/6] d_loss: 0.7076, g_loss: 3.34\n",
      "[1/6] d_loss: 1.524, g_loss: 0.9199\n",
      "[1/6] d_loss: 1.174, g_loss: 2.279\n",
      "[1/6] d_loss: 0.9667, g_loss: 1.218\n",
      "[1/6] d_loss: 1.558, g_loss: 0.6056\n",
      "[1/6] d_loss: 1.092, g_loss: 0.439\n",
      "[1/6] d_loss: 1.113, g_loss: 0.9388\n",
      "[1/6] d_loss: 1.156, g_loss: 1.228\n",
      "[1/6] d_loss: 1.09, g_loss: 2.031\n",
      "[1/6] d_loss: 1.206, g_loss: 1.082\n",
      "[1/6] d_loss: 1.073, g_loss: 0.8944\n",
      "[1/6] d_loss: 1.117, g_loss: 2.076\n",
      "[1/6] d_loss: 0.7886, g_loss: 1.972\n",
      "[1/6] d_loss: 0.8152, g_loss: 1.94\n",
      "[1/6] d_loss: 0.9183, g_loss: 1.975\n",
      "[1/6] d_loss: 1.043, g_loss: 2.265\n",
      "[1/6] d_loss: 1.07, g_loss: 0.8958\n",
      "[1/6] d_loss: 1.684, g_loss: 1.64\n",
      "[1/6] d_loss: 1.224, g_loss: 0.8005\n",
      "[1/6] d_loss: 1.131, g_loss: 0.9562\n",
      "[1/6] d_loss: 0.9422, g_loss: 1.537\n",
      "[1/6] d_loss: 0.7158, g_loss: 1.46\n",
      "[1/6] d_loss: 0.6539, g_loss: 2.663\n",
      "[1/6] d_loss: 0.8645, g_loss: 2.487\n",
      "[1/6] d_loss: 1.448, g_loss: 1.006\n",
      "[1/6] d_loss: 0.9176, g_loss: 1.072\n",
      "[1/6] d_loss: 1.274, g_loss: 1.134\n",
      "[1/6] d_loss: 1.283, g_loss: 0.5701\n",
      "[1/6] d_loss: 0.8668, g_loss: 2.941\n",
      "[1/6] d_loss: 0.8806, g_loss: 2.514\n",
      "[1/6] d_loss: 0.9624, g_loss: 1.716\n",
      "[1/6] d_loss: 0.6233, g_loss: 2.162\n",
      "[1/6] d_loss: 1.38, g_loss: 1.233\n",
      "[1/6] d_loss: 0.9373, g_loss: 2.409\n",
      "[2/6] d_loss: 0.9683, g_loss: 0.6926\n",
      "[2/6] d_loss: 0.7968, g_loss: 2.043\n",
      "[2/6] d_loss: 0.7259, g_loss: 2.097\n",
      "[2/6] d_loss: 0.965, g_loss: 2.341\n",
      "[2/6] d_loss: 0.9551, g_loss: 1.85\n",
      "[2/6] d_loss: 0.9094, g_loss: 2.232\n",
      "[2/6] d_loss: 1.2, g_loss: 1.731\n",
      "[2/6] d_loss: 1.504, g_loss: 2.5\n",
      "[2/6] d_loss: 1.028, g_loss: 2.214\n",
      "[2/6] d_loss: 0.7035, g_loss: 1.048\n",
      "[2/6] d_loss: 1.082, g_loss: 1.961\n",
      "[2/6] d_loss: 0.5271, g_loss: 1.867\n",
      "[2/6] d_loss: 1.144, g_loss: 2.794\n",
      "[2/6] d_loss: 0.822, g_loss: 0.8443\n",
      "[2/6] d_loss: 0.8567, g_loss: 1.07\n",
      "[2/6] d_loss: 1.338, g_loss: 0.6436\n",
      "[2/6] d_loss: 1.132, g_loss: 2.92\n",
      "[2/6] d_loss: 0.8691, g_loss: 1.859\n",
      "[2/6] d_loss: 0.6767, g_loss: 1.662\n",
      "[2/6] d_loss: 0.6806, g_loss: 2.134\n",
      "[2/6] d_loss: 1.038, g_loss: 2.01\n",
      "[2/6] d_loss: 0.9718, g_loss: 0.8705\n",
      "[2/6] d_loss: 0.5807, g_loss: 2.585\n",
      "[2/6] d_loss: 0.5565, g_loss: 1.789\n",
      "[2/6] d_loss: 0.738, g_loss: 1.572\n",
      "[2/6] d_loss: 1.445, g_loss: 0.892\n",
      "[2/6] d_loss: 0.9475, g_loss: 0.7077\n",
      "[2/6] d_loss: 0.665, g_loss: 2.879\n",
      "[2/6] d_loss: 0.6059, g_loss: 1.256\n",
      "[2/6] d_loss: 0.5231, g_loss: 1.81\n",
      "[2/6] d_loss: 0.8313, g_loss: 1.121\n",
      "[2/6] d_loss: 1.187, g_loss: 1.835\n",
      "[2/6] d_loss: 0.8321, g_loss: 2.27\n",
      "[2/6] d_loss: 0.8078, g_loss: 1.297\n",
      "[2/6] d_loss: 0.9811, g_loss: 1.499\n",
      "[2/6] d_loss: 0.624, g_loss: 1.313\n",
      "[2/6] d_loss: 0.6423, g_loss: 1.835\n",
      "[2/6] d_loss: 0.8033, g_loss: 1.88\n",
      "[2/6] d_loss: 0.9493, g_loss: 1.469\n",
      "[2/6] d_loss: 0.7777, g_loss: 1.632\n",
      "[2/6] d_loss: 1.1, g_loss: 1.75\n",
      "[2/6] d_loss: 0.7462, g_loss: 2.646\n",
      "[2/6] d_loss: 0.887, g_loss: 1.354\n",
      "[2/6] d_loss: 1.215, g_loss: 1.55\n",
      "[2/6] d_loss: 0.6942, g_loss: 3.105\n",
      "[2/6] d_loss: 0.8726, g_loss: 2.157\n",
      "[2/6] d_loss: 1.001, g_loss: 2.974\n",
      "[2/6] d_loss: 0.6169, g_loss: 0.7172\n",
      "[2/6] d_loss: 0.838, g_loss: 0.8297\n",
      "[2/6] d_loss: 0.8221, g_loss: 1.209\n",
      "[2/6] d_loss: 0.7965, g_loss: 2.376\n",
      "[2/6] d_loss: 1.065, g_loss: 1.913\n",
      "[2/6] d_loss: 0.9956, g_loss: 1.732\n",
      "[2/6] d_loss: 0.8721, g_loss: 1.437\n",
      "[2/6] d_loss: 0.7487, g_loss: 1.579\n",
      "[2/6] d_loss: 1.082, g_loss: 0.7644\n",
      "[2/6] d_loss: 0.9789, g_loss: 3.038\n",
      "[2/6] d_loss: 0.9436, g_loss: 1.571\n",
      "[2/6] d_loss: 1.2, g_loss: 1.742\n",
      "[2/6] d_loss: 0.8973, g_loss: 0.7874\n",
      "[2/6] d_loss: 0.6958, g_loss: 1.894\n",
      "[2/6] d_loss: 0.7119, g_loss: 3.397\n",
      "[2/6] d_loss: 0.6852, g_loss: 2.374\n",
      "[2/6] d_loss: 0.9736, g_loss: 1.134\n",
      "[2/6] d_loss: 0.8934, g_loss: 2.027\n",
      "[2/6] d_loss: 1.123, g_loss: 1.874\n",
      "[2/6] d_loss: 0.7485, g_loss: 1.194\n",
      "[2/6] d_loss: 1.416, g_loss: 1.872\n",
      "[3/6] d_loss: 0.8483, g_loss: 0.766\n",
      "[3/6] d_loss: 0.716, g_loss: 1.928\n",
      "[3/6] d_loss: 0.612, g_loss: 1.188\n",
      "[3/6] d_loss: 0.6201, g_loss: 2.088\n",
      "[3/6] d_loss: 1.051, g_loss: 1.499\n",
      "[3/6] d_loss: 0.8103, g_loss: 2.223\n",
      "[3/6] d_loss: 1.022, g_loss: 2.091\n",
      "[3/6] d_loss: 1.249, g_loss: 2.188\n",
      "[3/6] d_loss: 0.8198, g_loss: 1.866\n",
      "[3/6] d_loss: 0.7391, g_loss: 3.051\n",
      "[3/6] d_loss: 0.4684, g_loss: 2.125\n",
      "[3/6] d_loss: 0.6994, g_loss: 1.354\n",
      "[3/6] d_loss: 0.9691, g_loss: 1.661\n",
      "[3/6] d_loss: 1.272, g_loss: 0.9556\n",
      "[3/6] d_loss: 0.9038, g_loss: 2.943\n",
      "[3/6] d_loss: 0.8122, g_loss: 2.079\n",
      "[3/6] d_loss: 0.6703, g_loss: 1.141\n",
      "[3/6] d_loss: 0.6746, g_loss: 1.462\n",
      "[3/6] d_loss: 0.667, g_loss: 1.928\n",
      "[3/6] d_loss: 0.8091, g_loss: 0.7185\n",
      "[3/6] d_loss: 0.8455, g_loss: 2.016\n",
      "[3/6] d_loss: 0.7723, g_loss: 1.425\n",
      "[3/6] d_loss: 0.6685, g_loss: 1.142\n",
      "[3/6] d_loss: 0.8933, g_loss: 0.5354\n",
      "[3/6] d_loss: 0.874, g_loss: 2.198\n",
      "[3/6] d_loss: 0.6017, g_loss: 1.702\n",
      "[3/6] d_loss: 0.8684, g_loss: 1.822\n",
      "[3/6] d_loss: 0.839, g_loss: 2.226\n",
      "[3/6] d_loss: 0.6827, g_loss: 2.825\n",
      "[3/6] d_loss: 0.6756, g_loss: 1.402\n",
      "[3/6] d_loss: 0.8416, g_loss: 1.389\n",
      "[3/6] d_loss: 0.9318, g_loss: 2.98\n",
      "[3/6] d_loss: 0.9031, g_loss: 1.861\n",
      "[3/6] d_loss: 0.849, g_loss: 2.708\n",
      "[3/6] d_loss: 0.6285, g_loss: 1.958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/6] d_loss: 0.7138, g_loss: 1.816\n",
      "[3/6] d_loss: 0.8518, g_loss: 1.419\n",
      "[3/6] d_loss: 0.7815, g_loss: 1.873\n",
      "[3/6] d_loss: 1.162, g_loss: 2.126\n",
      "[3/6] d_loss: 0.8536, g_loss: 1.238\n",
      "[3/6] d_loss: 1.269, g_loss: 2.022\n",
      "[3/6] d_loss: 0.6432, g_loss: 2.398\n",
      "[3/6] d_loss: 0.7599, g_loss: 2.996\n",
      "[3/6] d_loss: 1.084, g_loss: 1.243\n",
      "[3/6] d_loss: 0.7075, g_loss: 1.837\n",
      "[3/6] d_loss: 1.136, g_loss: 1.301\n",
      "[3/6] d_loss: 1.073, g_loss: 2.315\n",
      "[3/6] d_loss: 1.031, g_loss: 1.637\n",
      "[3/6] d_loss: 1.376, g_loss: 1.977\n",
      "[3/6] d_loss: 0.9651, g_loss: 1.31\n",
      "[3/6] d_loss: 0.8327, g_loss: 2.057\n",
      "[3/6] d_loss: 0.5591, g_loss: 1.929\n",
      "[3/6] d_loss: 1.451, g_loss: 2.621\n",
      "[3/6] d_loss: 0.8639, g_loss: 2.023\n",
      "[3/6] d_loss: 0.8408, g_loss: 1.351\n",
      "[3/6] d_loss: 0.7619, g_loss: 1.175\n",
      "[3/6] d_loss: 0.8271, g_loss: 1.317\n",
      "[3/6] d_loss: 0.7408, g_loss: 1.295\n",
      "[3/6] d_loss: 1.441, g_loss: 2.734\n",
      "[3/6] d_loss: 0.9178, g_loss: 0.6831\n",
      "[3/6] d_loss: 1.346, g_loss: 2.813\n",
      "[3/6] d_loss: 1.055, g_loss: 2.138\n",
      "[3/6] d_loss: 1.12, g_loss: 2.567\n",
      "[3/6] d_loss: 0.6917, g_loss: 2.373\n",
      "[3/6] d_loss: 1.014, g_loss: 2.717\n",
      "[3/6] d_loss: 0.6974, g_loss: 2.412\n",
      "[3/6] d_loss: 0.7602, g_loss: 0.9882\n",
      "[3/6] d_loss: 0.9866, g_loss: 2.349\n",
      "[3/6] d_loss: 0.5992, g_loss: 2.357\n",
      "[3/6] d_loss: 0.8321, g_loss: 2.049\n",
      "[3/6] d_loss: 0.9939, g_loss: 1.393\n",
      "[3/6] d_loss: 1.202, g_loss: 1.111\n",
      "[3/6] d_loss: 0.7552, g_loss: 1.419\n",
      "[3/6] d_loss: 1.049, g_loss: 0.5693\n",
      "[3/6] d_loss: 0.6913, g_loss: 1.807\n",
      "[3/6] d_loss: 0.807, g_loss: 2.843\n",
      "[3/6] d_loss: 0.8264, g_loss: 2.317\n",
      "[3/6] d_loss: 1.352, g_loss: 2.732\n",
      "[3/6] d_loss: 0.8679, g_loss: 2.471\n",
      "[3/6] d_loss: 0.6293, g_loss: 2.278\n",
      "[3/6] d_loss: 0.8906, g_loss: 1.897\n",
      "[3/6] d_loss: 0.5635, g_loss: 1.412\n",
      "[3/6] d_loss: 0.9745, g_loss: 1.632\n",
      "[3/6] d_loss: 0.9514, g_loss: 1.499\n",
      "[3/6] d_loss: 0.5896, g_loss: 0.9848\n",
      "[3/6] d_loss: 1.048, g_loss: 0.8454\n",
      "[4/6] d_loss: 0.7295, g_loss: 2.027\n",
      "[4/6] d_loss: 1.193, g_loss: 1.326\n",
      "[4/6] d_loss: 0.5967, g_loss: 1.393\n",
      "[4/6] d_loss: 0.8144, g_loss: 1.07\n",
      "[4/6] d_loss: 1.184, g_loss: 1.818\n",
      "[4/6] d_loss: 0.9572, g_loss: 0.7005\n",
      "[4/6] d_loss: 0.7921, g_loss: 2.568\n",
      "[4/6] d_loss: 0.7727, g_loss: 1.201\n",
      "[4/6] d_loss: 0.8124, g_loss: 2.931\n",
      "[4/6] d_loss: 0.7763, g_loss: 1.054\n",
      "[4/6] d_loss: 0.9261, g_loss: 1.828\n",
      "[4/6] d_loss: 1.502, g_loss: 1.979\n",
      "[4/6] d_loss: 1.554, g_loss: 1.772\n",
      "[4/6] d_loss: 0.8624, g_loss: 1.321\n",
      "[4/6] d_loss: 0.73, g_loss: 2.298\n",
      "[4/6] d_loss: 0.9157, g_loss: 1.602\n",
      "[4/6] d_loss: 0.7492, g_loss: 1.579\n",
      "[4/6] d_loss: 0.8224, g_loss: 1.98\n",
      "[4/6] d_loss: 0.9862, g_loss: 1.789\n",
      "[4/6] d_loss: 0.8355, g_loss: 1.254\n",
      "[4/6] d_loss: 0.7968, g_loss: 1.049\n",
      "[4/6] d_loss: 0.7193, g_loss: 1.009\n",
      "[4/6] d_loss: 0.669, g_loss: 1.674\n",
      "[4/6] d_loss: 1.03, g_loss: 1.867\n",
      "[4/6] d_loss: 0.9248, g_loss: 2.559\n",
      "[4/6] d_loss: 0.5131, g_loss: 1.62\n",
      "[4/6] d_loss: 0.9634, g_loss: 2.259\n",
      "[4/6] d_loss: 1.033, g_loss: 0.607\n",
      "[4/6] d_loss: 1.536, g_loss: 0.5372\n",
      "[4/6] d_loss: 1.245, g_loss: 1.972\n",
      "[4/6] d_loss: 0.7412, g_loss: 1.239\n",
      "[4/6] d_loss: 0.724, g_loss: 1.583\n",
      "[4/6] d_loss: 0.8676, g_loss: 1.385\n",
      "[4/6] d_loss: 0.8868, g_loss: 2.664\n",
      "[4/6] d_loss: 1.005, g_loss: 2.768\n",
      "[4/6] d_loss: 0.7572, g_loss: 2.077\n",
      "[4/6] d_loss: 0.9732, g_loss: 1.296\n",
      "[4/6] d_loss: 0.3684, g_loss: 2.041\n",
      "[4/6] d_loss: 0.9257, g_loss: 3.123\n",
      "[4/6] d_loss: 0.697, g_loss: 1.161\n",
      "[4/6] d_loss: 0.5512, g_loss: 2.759\n",
      "[4/6] d_loss: 0.8444, g_loss: 1.488\n",
      "[4/6] d_loss: 0.9637, g_loss: 0.5019\n",
      "[4/6] d_loss: 1.197, g_loss: 0.8561\n",
      "[4/6] d_loss: 0.6915, g_loss: 3.92\n",
      "[4/6] d_loss: 0.7162, g_loss: 2.009\n",
      "[4/6] d_loss: 0.5669, g_loss: 1.738\n",
      "[4/6] d_loss: 0.6134, g_loss: 2.435\n",
      "[4/6] d_loss: 0.5387, g_loss: 1.603\n",
      "[4/6] d_loss: 0.653, g_loss: 2.539\n",
      "[4/6] d_loss: 0.9812, g_loss: 1.699\n",
      "[4/6] d_loss: 1.856, g_loss: 1.612\n",
      "[4/6] d_loss: 0.9362, g_loss: 3.021\n",
      "[4/6] d_loss: 1.301, g_loss: 2.207\n",
      "[4/6] d_loss: 0.7591, g_loss: 1.326\n",
      "[4/6] d_loss: 0.7657, g_loss: 1.375\n",
      "[4/6] d_loss: 0.5557, g_loss: 1.708\n",
      "[4/6] d_loss: 0.8503, g_loss: 2.023\n",
      "[4/6] d_loss: 0.7171, g_loss: 1.469\n",
      "[4/6] d_loss: 0.9265, g_loss: 1.08\n",
      "[4/6] d_loss: 0.6675, g_loss: 1.138\n",
      "[4/6] d_loss: 0.8253, g_loss: 1.865\n",
      "[5/6] d_loss: 0.699, g_loss: 1.853\n",
      "[5/6] d_loss: 0.8639, g_loss: 2.82\n",
      "[5/6] d_loss: 0.6248, g_loss: 1.547\n",
      "[5/6] d_loss: 0.7152, g_loss: 1.718\n",
      "[5/6] d_loss: 0.5747, g_loss: 1.598\n",
      "[5/6] d_loss: 0.9584, g_loss: 1.242\n",
      "[5/6] d_loss: 0.5152, g_loss: 3.186\n",
      "[5/6] d_loss: 0.6477, g_loss: 1.52\n",
      "[5/6] d_loss: 0.588, g_loss: 2.082\n",
      "[5/6] d_loss: 0.6917, g_loss: 1.592\n",
      "[5/6] d_loss: 0.5499, g_loss: 2.259\n",
      "[5/6] d_loss: 0.5079, g_loss: 2.134\n",
      "[5/6] d_loss: 1.524, g_loss: 0.5548\n",
      "[5/6] d_loss: 0.5442, g_loss: 1.579\n",
      "[5/6] d_loss: 0.7231, g_loss: 2.636\n",
      "[5/6] d_loss: 0.6341, g_loss: 1.813\n",
      "[5/6] d_loss: 1.108, g_loss: 2.628\n",
      "[5/6] d_loss: 0.8647, g_loss: 3.329\n",
      "[5/6] d_loss: 0.8321, g_loss: 1.003\n",
      "[5/6] d_loss: 0.7686, g_loss: 2.168\n",
      "[5/6] d_loss: 0.4644, g_loss: 2.68\n",
      "[5/6] d_loss: 0.5584, g_loss: 2.377\n",
      "[5/6] d_loss: 0.9977, g_loss: 0.7838\n",
      "[5/6] d_loss: 0.6446, g_loss: 2.087\n",
      "[5/6] d_loss: 0.9079, g_loss: 2.364\n",
      "[5/6] d_loss: 0.7737, g_loss: 1.784\n",
      "[5/6] d_loss: 0.9371, g_loss: 0.4992\n",
      "[5/6] d_loss: 0.7739, g_loss: 2.144\n",
      "[5/6] d_loss: 0.6427, g_loss: 1.778\n",
      "[5/6] d_loss: 0.8172, g_loss: 1.091\n",
      "[5/6] d_loss: 0.7015, g_loss: 1.64\n",
      "[5/6] d_loss: 0.9106, g_loss: 2.325\n",
      "[5/6] d_loss: 0.6139, g_loss: 2.115\n",
      "[5/6] d_loss: 0.8001, g_loss: 2.022\n",
      "[5/6] d_loss: 0.773, g_loss: 1.706\n",
      "[5/6] d_loss: 0.9793, g_loss: 2.44\n",
      "[5/6] d_loss: 0.699, g_loss: 1.505\n",
      "[5/6] d_loss: 0.7642, g_loss: 1.242\n",
      "[5/6] d_loss: 0.7462, g_loss: 1.365\n",
      "[5/6] d_loss: 0.5295, g_loss: 1.827\n",
      "[5/6] d_loss: 1.082, g_loss: 1.259\n",
      "[5/6] d_loss: 0.7159, g_loss: 2.453\n",
      "[5/6] d_loss: 0.7086, g_loss: 2.644\n",
      "[5/6] d_loss: 1.206, g_loss: 3.753\n",
      "[5/6] d_loss: 0.977, g_loss: 0.5837\n",
      "[5/6] d_loss: 0.7517, g_loss: 1.014\n",
      "[5/6] d_loss: 0.7154, g_loss: 1.96\n",
      "[5/6] d_loss: 0.9991, g_loss: 1.12\n",
      "[5/6] d_loss: 0.7314, g_loss: 2.365\n",
      "[5/6] d_loss: 0.8146, g_loss: 1.276\n",
      "[5/6] d_loss: 0.665, g_loss: 2.209\n",
      "[5/6] d_loss: 1.724, g_loss: 2.127\n",
      "[5/6] d_loss: 0.5553, g_loss: 1.39\n",
      "[5/6] d_loss: 0.8923, g_loss: 1.037\n",
      "[5/6] d_loss: 0.7459, g_loss: 2.192\n",
      "[5/6] d_loss: 0.6947, g_loss: 1.499\n",
      "[5/6] d_loss: 0.9167, g_loss: 1.989\n",
      "[5/6] d_loss: 0.6509, g_loss: 2.827\n",
      "[5/6] d_loss: 0.7208, g_loss: 2.268\n",
      "[5/6] d_loss: 1.267, g_loss: 3.05\n",
      "[5/6] d_loss: 0.8009, g_loss: 2.723\n",
      "[5/6] d_loss: 0.8755, g_loss: 2.388\n",
      "[5/6] d_loss: 0.8707, g_loss: 2.705\n",
      "[5/6] d_loss: 0.8858, g_loss: 1.289\n",
      "[5/6] d_loss: 0.7269, g_loss: 1.594\n",
      "[5/6] d_loss: 0.7479, g_loss: 1.18\n",
      "[5/6] d_loss: 0.5819, g_loss: 1.413\n",
      "[5/6] d_loss: 0.6725, g_loss: 1.746\n",
      "[5/6] d_loss: 0.5323, g_loss: 2.532\n",
      "[5/6] d_loss: 0.7582, g_loss: 2.211\n",
      "[5/6] d_loss: 0.9813, g_loss: 1.694\n",
      "[5/6] d_loss: 0.8718, g_loss: 2.301\n",
      "[5/6] d_loss: 1.084, g_loss: 2.985\n",
      "[5/6] d_loss: 0.6527, g_loss: 1.14\n",
      "[5/6] d_loss: 0.6465, g_loss: 2.796\n",
      "[5/6] d_loss: 0.6545, g_loss: 1.522\n",
      "[5/6] d_loss: 0.496, g_loss: 1.71\n",
      "[5/6] d_loss: 0.9099, g_loss: 2.381\n",
      "[5/6] d_loss: 0.6883, g_loss: 2.397\n",
      "[5/6] d_loss: 0.6258, g_loss: 2.273\n",
      "[5/6] d_loss: 0.8373, g_loss: 2.106\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Number of parameter for the Generator and discriminator respectively:\n",
      "\n",
      "29545\n",
      "\n",
      "27393\n",
      "\n",
      "\n",
      "Number of Epochs and steps for each epoch:\n",
      "\n",
      "epochs:  6    batches:  7347\n",
      "\n",
      "\n",
      "Time Taken:\n",
      "00:07:05\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "\n",
    "#from gan_libs.DCGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.LSGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.SNGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.WGAN_GP import build_generator, build_discriminator, build_functions\n",
    "\n",
    "from utils.common import set_gpu_config, predict_images\n",
    "from utils.draw_pose import draw_pose\n",
    "import numpy as np\n",
    "\n",
    "#set_gpu_config(\"0\",0.5)\n",
    "\n",
    "epoch = 50 + 1\n",
    "image_size = (1,1,105)\n",
    "noise_size = (1,1,5)\n",
    "batch_size = 16\n",
    "\n",
    "x_train = myData\n",
    "np.random.shuffle(x_train)\n",
    "\n",
    "generator = build_generator(noise_size)\n",
    "print('gen params:',generator.count_params())\n",
    "discriminator = build_discriminator(image_size)\n",
    "print('dis params:',discriminator.count_params())\n",
    "d_train, g_train = build_functions(batch_size, noise_size, image_size, generator, discriminator)\n",
    "\n",
    "# generator.load_weights(\"e30_generator.h5\".format(e))\n",
    "# discriminator.load_weights(\"e30_discriminator.h5\".format(e))\n",
    "\n",
    "\n",
    "number_of_all_data = x_train.shape[0]\n",
    "number_of_batches = int(number_of_all_data/batch_size)\n",
    "print('Number of Batches passed in each epoch: ',number_of_batches)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "is_first_epoch = True\n",
    "\n",
    "for e in range(epoch):\n",
    "    index = 0\n",
    "    for batch in range(number_of_batches):\n",
    "        real_images = x_train[index:index+batch_size]\n",
    "        index =+ batch_size\n",
    "        real_images.shape = (batch_size,1,1,105)\n",
    "        d_loss, = d_train([real_images, 1])\n",
    "        g_loss, = g_train([real_images, 1])\n",
    "        if np.random.randint(low = 0, high = 100) == 1:   \n",
    "            print (\"[{0}/{1}] d_loss: {2:.4}, g_loss: {3:.4}\".format(e, epoch, d_loss, g_loss))\n",
    "            #generating a sample\n",
    "            image = generator.predict(np.zeros(shape=(1,3)))\n",
    "            image = np.array(image)\n",
    "            draw_pose(image.reshape(105),'output',\"_ThreeLatents_e{0}_batch{1}\".format(e,batch))\n",
    "    \n",
    "    if(is_first_epoch):\n",
    "        elapsed_time = time.time() - start_time \n",
    "        print('\\n\\nTime Taken for single epoch:')\n",
    "        print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "        is_first_epoch = False\n",
    "    \n",
    "    if e % 50 == 0 and e > 0:\n",
    "        generator.save_weights(\"_ThreeLatents_e{0}_generator.h5\".format(e))\n",
    "        discriminator.save_weights(\"_ThreeLatents_e{0}_discriminator.h5\".format(e))\n",
    " \n",
    "#just monitoring:\n",
    "##########################################################################################\n",
    "elapsed_time = time.time() - start_time \n",
    "print('\\n\\n\\n\\nNumber of parameter for the Generator and discriminator respectively:\\n')\n",
    "print(generator.count_params())\n",
    "print('')\n",
    "print(discriminator.count_params())\n",
    "print('\\n\\nNumber of Epochs and steps for each epoch:\\n')\n",
    "print('epochs: ',epoch, '   batches: ', number_of_batches)\n",
    "\n",
    "print('\\n\\nTime Taken:')\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "##########################################################################################\n",
    "#NOTE: previously in each epoch 1000 steps were iterated. in each iteration data was permitated and a batch was chosen. \n",
    "#now data is shuffled first and there are number_of_data/batch_size steps to be passed in a single epoch. \n",
    "# since 200 epochs and 1000 steps each was used, now 25 epochs and ˜7300 steps is used so the balance is kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,GlobalAveragePooling2D,LeakyReLU,Conv2DTranspose,Activation,BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras import initializers\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "\n",
    "\n",
    "noise_dim = 2\n",
    "\n",
    "def build_generator(input_shape):\n",
    "\n",
    "    generator = Sequential()\n",
    "    \n",
    "    generator.add(Dense(256,\n",
    "                        input_dim = noise_dim))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "#     generator.add(Dense(256))\n",
    "#     generator.add(BatchNormalization())\n",
    "#     generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    generator.add(Dense(105, activation='tanh'))\n",
    "    return generator\n",
    "\n",
    "\n",
    "def build_discriminator(input_shape):\n",
    "\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Dense(256,\n",
    "                            input_dim=105))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "    \n",
    "    \n",
    "#     discriminator.add(Dense(256))\n",
    "#     discriminator.add(LeakyReLU(0.2))\n",
    "#     discriminator.add(Dropout(0.3))\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return discriminator\n",
    "\n",
    "def build_functions(batch_size, noise_size, image_size, generator, discriminator):\n",
    "\n",
    "    noise = K.random_normal((batch_size,) + noise_size,0.0,1.0,\"float32\")\n",
    "    real_image = K.placeholder((batch_size,) + image_size)\n",
    "\n",
    "    fake_image = generator(noise)\n",
    "\n",
    "    d_input = K.concatenate([real_image, fake_image], axis=0)\n",
    "    pred_real, pred_fake = tf.split(discriminator(d_input), num_or_size_splits = 2, axis = 0)\n",
    "\n",
    "    pred_real = K.clip(pred_real,K.epsilon(),1-K.epsilon())\n",
    "    pred_fake = K.clip(pred_fake,K.epsilon(),1-K.epsilon())\n",
    "\n",
    "    d_loss = -(K.mean(K.log(pred_real)) + K.mean(K.log(1-pred_fake)))\n",
    "    g_loss = -K.mean(K.log(pred_fake))\n",
    "\n",
    "    # get updates of mean and variance in batch normalization layers\n",
    "    d_updates = discriminator.get_updates_for([d_input])\n",
    "    g_updates = generator.get_updates_for([noise])\n",
    "\n",
    "    d_training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(d_loss, discriminator.trainable_weights)\n",
    "    d_train = K.function([real_image, K.learning_phase()], [d_loss],d_updates + d_training_updates)\n",
    "\n",
    "    g_training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(g_loss, generator.trainable_weights)\n",
    "    g_train = K.function([real_image, K.learning_phase()], [g_loss], g_updates + g_training_updates)\n",
    "\n",
    "    return d_train,g_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "#from gan_libs.DCGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.LSGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.SNGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.WGAN_GP import build_generator, build_discriminator, build_functions\n",
    "\n",
    "from utils.common import set_gpu_config, predict_images\n",
    "from utils.draw_pose import draw_pose\n",
    "import numpy as np\n",
    "\n",
    "#set_gpu_config(\"0\",0.5)\n",
    "\n",
    "epoch = 50 + 1\n",
    "image_size = (1,1,105)\n",
    "noise_size = (1,1,5)\n",
    "batch_size = 16\n",
    "\n",
    "x_train = myData\n",
    "np.random.shuffle(x_train)\n",
    "\n",
    "generator = build_generator(noise_size)\n",
    "print('gen params:',generator.count_params())\n",
    "discriminator = build_discriminator(image_size)\n",
    "print('dis params:',discriminator.count_params())\n",
    "d_train, g_train = build_functions(batch_size, noise_size, image_size, generator, discriminator)\n",
    "\n",
    "# generator.load_weights(\"e30_generator.h5\".format(e))\n",
    "# discriminator.load_weights(\"e30_discriminator.h5\".format(e))\n",
    "\n",
    "\n",
    "number_of_all_data = x_train.shape[0]\n",
    "number_of_batches = int(number_of_all_data/batch_size)\n",
    "print('Number of Batches passed in each epoch: ',number_of_batches)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "is_first_epoch = True\n",
    "\n",
    "for e in range(epoch):\n",
    "    index = 0\n",
    "    for batch in range(number_of_batches):\n",
    "        real_images = x_train[index:index+batch_size]\n",
    "        index =+ batch_size\n",
    "        real_images.shape = (batch_size,1,1,105)\n",
    "        d_loss, = d_train([real_images, 1])\n",
    "        g_loss, = g_train([real_images, 1])\n",
    "        if np.random.randint(low = 0, high = 100) == 1:   \n",
    "            print (\"[{0}/{1}] d_loss: {2:.4}, g_loss: {3:.4}\".format(e, epoch, d_loss, g_loss))\n",
    "            #generating a sample\n",
    "            image = generator.predict(np.zeros(shape=(1,2)))\n",
    "            image = np.array(image)\n",
    "            draw_pose(image.reshape(105),'output',\"_TwoLatents_e{0}_batch{1}\".format(e,batch))\n",
    "    \n",
    "    if(is_first_epoch):\n",
    "        elapsed_time = time.time() - start_time \n",
    "        print('\\n\\nTime Taken for single epoch:')\n",
    "        print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "        is_first_epoch = False\n",
    "    \n",
    "    if e % 50 == 0 and e > 0:\n",
    "        generator.save_weights(\"_TwoLatents_e{0}_generator.h5\".format(e))\n",
    "        discriminator.save_weights(\"_TwoLatents_e{0}_discriminator.h5\".format(e))\n",
    " \n",
    "#just monitoring:\n",
    "##########################################################################################\n",
    "elapsed_time = time.time() - start_time \n",
    "print('\\n\\n\\n\\nNumber of parameter for the Generator and discriminator respectively:\\n')\n",
    "print(generator.count_params())\n",
    "print('')\n",
    "print(discriminator.count_params())\n",
    "print('\\n\\nNumber of Epochs and steps for each epoch:\\n')\n",
    "print('epochs: ',epoch, '   batches: ', number_of_batches)\n",
    "\n",
    "print('\\n\\nTime Taken:')\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "##########################################################################################\n",
    "#NOTE: previously in each epoch 1000 steps were iterated. in each iteration data was permitated and a batch was chosen. \n",
    "#now data is shuffled first and there are number_of_data/batch_size steps to be passed in a single epoch. \n",
    "# since 200 epochs and 1000 steps each was used, now 25 epochs and ˜7300 steps is used so the balance is kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,GlobalAveragePooling2D,LeakyReLU,Conv2DTranspose,Activation,BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras import initializers\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "\n",
    "\n",
    "noise_dim = 1\n",
    "\n",
    "def build_generator(input_shape):\n",
    "\n",
    "    generator = Sequential()\n",
    "    \n",
    "    generator.add(Dense(256,\n",
    "                        input_dim = noise_dim))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "#     generator.add(Dense(256))\n",
    "#     generator.add(BatchNormalization())\n",
    "#     generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    generator.add(Dense(105, activation='tanh'))\n",
    "    return generator\n",
    "\n",
    "\n",
    "def build_discriminator(input_shape):\n",
    "\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Dense(256,\n",
    "                            input_dim=105))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "    \n",
    "    \n",
    "#     discriminator.add(Dense(256))\n",
    "#     discriminator.add(LeakyReLU(0.2))\n",
    "#     discriminator.add(Dropout(0.3))\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return discriminator\n",
    "\n",
    "def build_functions(batch_size, noise_size, image_size, generator, discriminator):\n",
    "\n",
    "    noise = K.random_normal((batch_size,) + noise_size,0.0,1.0,\"float32\")\n",
    "    real_image = K.placeholder((batch_size,) + image_size)\n",
    "\n",
    "    fake_image = generator(noise)\n",
    "\n",
    "    d_input = K.concatenate([real_image, fake_image], axis=0)\n",
    "    pred_real, pred_fake = tf.split(discriminator(d_input), num_or_size_splits = 2, axis = 0)\n",
    "\n",
    "    pred_real = K.clip(pred_real,K.epsilon(),1-K.epsilon())\n",
    "    pred_fake = K.clip(pred_fake,K.epsilon(),1-K.epsilon())\n",
    "\n",
    "    d_loss = -(K.mean(K.log(pred_real)) + K.mean(K.log(1-pred_fake)))\n",
    "    g_loss = -K.mean(K.log(pred_fake))\n",
    "\n",
    "    # get updates of mean and variance in batch normalization layers\n",
    "    d_updates = discriminator.get_updates_for([d_input])\n",
    "    g_updates = generator.get_updates_for([noise])\n",
    "\n",
    "    d_training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(d_loss, discriminator.trainable_weights)\n",
    "    d_train = K.function([real_image, K.learning_phase()], [d_loss],d_updates + d_training_updates)\n",
    "\n",
    "    g_training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(g_loss, generator.trainable_weights)\n",
    "    g_train = K.function([real_image, K.learning_phase()], [g_loss], g_updates + g_training_updates)\n",
    "\n",
    "    return d_train,g_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "#from gan_libs.DCGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.LSGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.SNGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.WGAN_GP import build_generator, build_discriminator, build_functions\n",
    "\n",
    "from utils.common import set_gpu_config, predict_images\n",
    "from utils.draw_pose import draw_pose\n",
    "import numpy as np\n",
    "\n",
    "#set_gpu_config(\"0\",0.5)\n",
    "\n",
    "epoch = 50 + 1\n",
    "image_size = (1,1,105)\n",
    "noise_size = (1,1,5)\n",
    "batch_size = 16\n",
    "\n",
    "x_train = myData\n",
    "np.random.shuffle(x_train)\n",
    "\n",
    "generator = build_generator(noise_size)\n",
    "print('gen params:',generator.count_params())\n",
    "discriminator = build_discriminator(image_size)\n",
    "print('dis params:',discriminator.count_params())\n",
    "d_train, g_train = build_functions(batch_size, noise_size, image_size, generator, discriminator)\n",
    "\n",
    "# generator.load_weights(\"e30_generator.h5\".format(e))\n",
    "# discriminator.load_weights(\"e30_discriminator.h5\".format(e))\n",
    "\n",
    "\n",
    "number_of_all_data = x_train.shape[0]\n",
    "number_of_batches = int(number_of_all_data/batch_size)\n",
    "print('Number of Batches passed in each epoch: ',number_of_batches)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "is_first_epoch = True\n",
    "\n",
    "for e in range(epoch):\n",
    "    index = 0\n",
    "    for batch in range(number_of_batches):\n",
    "        real_images = x_train[index:index+batch_size]\n",
    "        index =+ batch_size\n",
    "        real_images.shape = (batch_size,1,1,105)\n",
    "        d_loss, = d_train([real_images, 1])\n",
    "        g_loss, = g_train([real_images, 1])\n",
    "        if np.random.randint(low = 0, high = 100) == 1:   \n",
    "            print (\"[{0}/{1}] d_loss: {2:.4}, g_loss: {3:.4}\".format(e, epoch, d_loss, g_loss))\n",
    "            #generating a sample\n",
    "            image = generator.predict(np.zeros(shape=(1,1)))\n",
    "            image = np.array(image)\n",
    "            draw_pose(image.reshape(105),'output',\"_OneLatent_1_e{0}_batch{1}\".format(e,batch))\n",
    "    \n",
    "    if(is_first_epoch):\n",
    "        elapsed_time = time.time() - start_time \n",
    "        print('\\n\\nTime Taken for single epoch:')\n",
    "        print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "        is_first_epoch = False\n",
    "    \n",
    "    if e % 50 == 0 and e > 0:\n",
    "        generator.save_weights(\"_OneLatent_1_e{0}_generator.h5\".format(e))\n",
    "        discriminator.save_weights(\"_OneLatent_1_e{0}_discriminator.h5\".format(e))\n",
    " \n",
    "#just monitoring:\n",
    "##########################################################################################\n",
    "elapsed_time = time.time() - start_time \n",
    "print('\\n\\n\\n\\nNumber of parameter for the Generator and discriminator respectively:\\n')\n",
    "print(generator.count_params())\n",
    "print('')\n",
    "print(discriminator.count_params())\n",
    "print('\\n\\nNumber of Epochs and steps for each epoch:\\n')\n",
    "print('epochs: ',epoch, '   batches: ', number_of_batches)\n",
    "\n",
    "print('\\n\\nTime Taken:')\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "##########################################################################################\n",
    "#NOTE: previously in each epoch 1000 steps were iterated. in each iteration data was permitated and a batch was chosen. \n",
    "#now data is shuffled first and there are number_of_data/batch_size steps to be passed in a single epoch. \n",
    "# since 200 epochs and 1000 steps each was used, now 25 epochs and ˜7300 steps is used so the balance is kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,GlobalAveragePooling2D,LeakyReLU,Conv2DTranspose,Activation,BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.layers import Dense\n",
    "from keras import initializers\n",
    "from keras.layers.core import Dropout\n",
    "\n",
    "\n",
    "\n",
    "noise_dim = 1\n",
    "\n",
    "def build_generator(input_shape):\n",
    "\n",
    "    generator = Sequential()\n",
    "    \n",
    "    generator.add(Dense(256,\n",
    "                        input_dim = noise_dim))\n",
    "    generator.add(BatchNormalization())\n",
    "    generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "#     generator.add(Dense(256))\n",
    "#     generator.add(BatchNormalization())\n",
    "#     generator.add(LeakyReLU(0.2))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    generator.add(Dense(105, activation='tanh'))\n",
    "    return generator\n",
    "\n",
    "\n",
    "def build_discriminator(input_shape):\n",
    "\n",
    "    discriminator = Sequential()\n",
    "    discriminator.add(Dense(256,\n",
    "                            input_dim=105))\n",
    "    discriminator.add(LeakyReLU(0.2))\n",
    "    discriminator.add(Dropout(0.3))\n",
    "    \n",
    "    \n",
    "#     discriminator.add(Dense(256))\n",
    "#     discriminator.add(LeakyReLU(0.2))\n",
    "#     discriminator.add(Dropout(0.3))\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "    \n",
    "    discriminator.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    return discriminator\n",
    "\n",
    "def build_functions(batch_size, noise_size, image_size, generator, discriminator):\n",
    "\n",
    "    noise = K.random_normal((batch_size,) + noise_size,0.0,3.0,\"float32\")\n",
    "    real_image = K.placeholder((batch_size,) + image_size)\n",
    "\n",
    "    fake_image = generator(noise)\n",
    "\n",
    "    d_input = K.concatenate([real_image, fake_image], axis=0)\n",
    "    pred_real, pred_fake = tf.split(discriminator(d_input), num_or_size_splits = 2, axis = 0)\n",
    "\n",
    "    pred_real = K.clip(pred_real,K.epsilon(),1-K.epsilon())\n",
    "    pred_fake = K.clip(pred_fake,K.epsilon(),1-K.epsilon())\n",
    "\n",
    "    d_loss = -(K.mean(K.log(pred_real)) + K.mean(K.log(1-pred_fake)))\n",
    "    g_loss = -K.mean(K.log(pred_fake))\n",
    "\n",
    "    # get updates of mean and variance in batch normalization layers\n",
    "    d_updates = discriminator.get_updates_for([d_input])\n",
    "    g_updates = generator.get_updates_for([noise])\n",
    "\n",
    "    d_training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(d_loss, discriminator.trainable_weights)\n",
    "    d_train = K.function([real_image, K.learning_phase()], [d_loss],d_updates + d_training_updates)\n",
    "\n",
    "    g_training_updates = Adam(lr=0.0001, beta_1=0.0, beta_2=0.9).get_updates(g_loss, generator.trainable_weights)\n",
    "    g_train = K.function([real_image, K.learning_phase()], [g_loss], g_updates + g_training_updates)\n",
    "\n",
    "    return d_train,g_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "#from gan_libs.DCGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.LSGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.SNGAN import build_generator, build_discriminator, build_functions\n",
    "# from gan_libs.WGAN_GP import build_generator, build_discriminator, build_functions\n",
    "\n",
    "from utils.common import set_gpu_config, predict_images\n",
    "from utils.draw_pose import draw_pose\n",
    "import numpy as np\n",
    "\n",
    "#set_gpu_config(\"0\",0.5)\n",
    "\n",
    "epoch = 50 + 1\n",
    "image_size = (1,1,105)\n",
    "noise_size = (1,1,5)\n",
    "batch_size = 16\n",
    "\n",
    "x_train = myData\n",
    "np.random.shuffle(x_train)\n",
    "\n",
    "generator = build_generator(noise_size)\n",
    "print('gen params:',generator.count_params())\n",
    "discriminator = build_discriminator(image_size)\n",
    "print('dis params:',discriminator.count_params())\n",
    "d_train, g_train = build_functions(batch_size, noise_size, image_size, generator, discriminator)\n",
    "\n",
    "# generator.load_weights(\"e30_generator.h5\".format(e))\n",
    "# discriminator.load_weights(\"e30_discriminator.h5\".format(e))\n",
    "\n",
    "\n",
    "number_of_all_data = x_train.shape[0]\n",
    "number_of_batches = int(number_of_all_data/batch_size)\n",
    "print('Number of Batches passed in each epoch: ',number_of_batches)\n",
    "\n",
    "import time\n",
    "start_time = time.time()\n",
    "is_first_epoch = True\n",
    "\n",
    "for e in range(epoch):\n",
    "    index = 0\n",
    "    for batch in range(number_of_batches):\n",
    "        real_images = x_train[index:index+batch_size]\n",
    "        index =+ batch_size\n",
    "        real_images.shape = (batch_size,1,1,105)\n",
    "        d_loss, = d_train([real_images, 1])\n",
    "        g_loss, = g_train([real_images, 1])\n",
    "        if np.random.randint(low = 0, high = 100) == 1:   \n",
    "            print (\"[{0}/{1}] d_loss: {2:.4}, g_loss: {3:.4}\".format(e, epoch, d_loss, g_loss))\n",
    "            #generating a sample\n",
    "            image = generator.predict(np.zeros(shape=(1,1)))\n",
    "            image = np.array(image)\n",
    "            draw_pose(image.reshape(105),'output',\"_OneLatent_3_e{0}_batch{1}\".format(e,batch))\n",
    "    \n",
    "    if(is_first_epoch):\n",
    "        elapsed_time = time.time() - start_time \n",
    "        print('\\n\\nTime Taken for single epoch:')\n",
    "        print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "        is_first_epoch = False\n",
    "    \n",
    "    if e % 50 == 0 and e > 0:\n",
    "        generator.save_weights(\"_OneLatent_3_e{0}_generator.h5\".format(e))\n",
    "        discriminator.save_weights(\"_OneLatent_3_e{0}_discriminator.h5\".format(e))\n",
    " \n",
    "#just monitoring:\n",
    "##########################################################################################\n",
    "elapsed_time = time.time() - start_time \n",
    "print('\\n\\n\\n\\nNumber of parameter for the Generator and discriminator respectively:\\n')\n",
    "print(generator.count_params())\n",
    "print('')\n",
    "print(discriminator.count_params())\n",
    "print('\\n\\nNumber of Epochs and steps for each epoch:\\n')\n",
    "print('epochs: ',epoch, '   batches: ', number_of_batches)\n",
    "\n",
    "print('\\n\\nTime Taken:')\n",
    "print(time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time)))\n",
    "##########################################################################################\n",
    "#NOTE: previously in each epoch 1000 steps were iterated. in each iteration data was permitated and a batch was chosen. \n",
    "#now data is shuffled first and there are number_of_data/batch_size steps to be passed in a single epoch. \n",
    "# since 200 epochs and 1000 steps each was used, now 25 epochs and ˜7300 steps is used so the balance is kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[37mcbrc-All-Series\u001b[m  Mon May  6 14:40:03 2019\n",
      "\u001b[36m[0]\u001b[m \u001b[34mGeForce GTX 1080 Ti\u001b[m |\u001b[1m\u001b[31m 53'C\u001b[m, \u001b[32m  0 %\u001b[m | \u001b[36m\u001b[1m\u001b[33m 6283\u001b[m / \u001b[33m11172\u001b[m MB | \u001b[1m\u001b[30mcbrc\u001b[m(\u001b[33m5961M\u001b[m) \u001b[1m\u001b[30mgdm\u001b[m(\u001b[33m16M\u001b[m) \u001b[1m\u001b[30mgdm\u001b[m(\u001b[33m50M\u001b[m) \u001b[1m\u001b[30mcbrc\u001b[m(\u001b[33m114M\u001b[m) \u001b[1m\u001b[30mcbrc\u001b[m(\u001b[33m136M\u001b[m)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "    #gpu details:\n",
    "    ################----------------------------\n",
    "from six.moves import cStringIO as StringIO\n",
    "import gpustat\n",
    "\n",
    "gpustats = gpustat.new_query()\n",
    "fp = StringIO()\n",
    "gpustats.print_formatted(\n",
    "     fp=fp, no_color=False, show_user=False,\n",
    "     show_cmd=False, show_pid=False, show_power=False, show_fan_speed=False)\n",
    "\n",
    "result = fp.getvalue()\n",
    "print('\\n\\n')\n",
    "print(result)\n",
    "    ################----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.load_weights(\"e400_generator.h5\".format(e))\n",
    "discriminator.load_weights(\"e400_discriminator.h5\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = -1;\n",
    "for i in np.linspace(-3,3,100):\n",
    "    z+=1\n",
    "    x= np.array((-i,0,0,i,0)).reshape(1,5)\n",
    "    image = generator.predict(x)\n",
    "    image = np.array(image)\n",
    "    draw_pose(image.reshape(105),'output',\"e{0}\".format(z))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
